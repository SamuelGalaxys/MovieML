{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68792497-4f9b-4951-8040-55f214459241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributor 리스트가 distributors_list.txt 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "csv_file_path = '0530_dataset\\preprosessing_ver2.csv'\n",
    "output_txt_file_path = 'distributors_list.txt'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Distributor 컬럼에서 중복 제거한 값들을 리스트로 저장\n",
    "distributors = set()\n",
    "for distributors_str in df['Distributor']:\n",
    "    for distributor in distributors_str.split(','):\n",
    "        distributors.add(distributor.strip())\n",
    "\n",
    "# 텍스트 파일로 내보내기\n",
    "with open(output_txt_file_path, 'w') as file:\n",
    "    for distributor in sorted(distributors):\n",
    "        file.write(f\"{distributor}\\n\")\n",
    "\n",
    "print(f\"Distributor 리스트가 {output_txt_file_path} 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367473ff-8eb6-4c70-bbb6-285a8a6b443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributor와 평가 컬럼이 포함된 CSV 파일이 distributors.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 주어진 텍스트 데이터를 그대로 문자열로 저장\n",
    "data = \"\"\"(주)넥스트엔터테인먼트월드(NEW), A\n",
    "(주)누리픽쳐스, D\n",
    "(주)대교 미디어콘텐츠사업본부, D\n",
    "(주)디스테이션, C\n",
    "(주)라이크콘텐츠, D\n",
    "(주)레드아이스 엔터테인먼트, D\n",
    "(주)마인드마크, D\n",
    "(주)명필름, D\n",
    "(주)무비다이브, D\n",
    "(주)미디어캐슬, C\n",
    "(주)바른손이앤에이, D\n",
    "(주)바이포엠스튜디오, D\n",
    "(주)박수엔터테인먼트, C\n",
    "(주)버킷스튜디오, D\n",
    "(주)블루라벨픽쳐스, D\n",
    "(주)쇼박스, A\n",
    "(주)스마일이엔티, B\n",
    "(주)스튜디오 산타클로스엔터테인먼트, D\n",
    "(주)스튜디오디에이치엘, D\n",
    "(주)시네마6411, D\n",
    "(주)시네마달, D\n",
    "(주)싸이더스, B\n",
    "(주)씨네필운, D\n",
    "(주)씨제이이엔엠, A\n",
    "(주)아센디오, D\n",
    "(주)아이오케이컴퍼니, D\n",
    "(주)애니플러스, C\n",
    "(주)에이스메이커무비웍스, B\n",
    "(주)엣나인필름, B\n",
    "(주)영화사 그램, D\n",
    "(주)영화사 안다미로, D\n",
    "(주)영화사 진진, C\n",
    "(주)영화특별시에스엠씨, D\n",
    "(주)올스타엔터테인먼트, C\n",
    "(주)이놀미디어, D\n",
    "(주)제이앤씨미디어그룹, D\n",
    "(주)케이티알파, D\n",
    "(주)콘텐츠지오, D\n",
    "(주)키다리스튜디오, B\n",
    "(주)티캐스트, C\n",
    "(주)팝엔터테인먼트, C\n",
    "(주)플레이그램, D\n",
    "(주)하이스트레인저, D\n",
    "(주)홈초이스, D\n",
    "CGV ICECON, A\n",
    "M&M 인터내셔널, C\n",
    "TCO(주)더콘텐츠온, C\n",
    "그린나래미디어(주), C\n",
    "다큐스토리, D\n",
    "더핑크퐁컴퍼니(주), D\n",
    "롯데컬처웍스(주)롯데시네마, A\n",
    "롯데컬처웍스(주)롯데엔터테인먼트, A\n",
    "롯데컬처웍스(주)롯시플, A\n",
    "리바이브콘텐츠 주식회사, D\n",
    "메가박스중앙(주), A\n",
    "미디어나무(주), D\n",
    "소니픽쳐스엔터테인먼트코리아주식회사극장배급지점, A\n",
    "스튜디오 에이드, D\n",
    "스튜디오두마, D\n",
    "씨제이 씨지브이(CJ CGV)(주), A\n",
    "씨제이포디플렉스 주식회사, A\n",
    "에스엠지홀딩스 주식회사, D\n",
    "오드, C\n",
    "와이드 릴리즈(주), C\n",
    "워너브러더스 코리아(주), A\n",
    "워터홀컴퍼니(주), C\n",
    "월트디즈니컴퍼니코리아 유한책임회사, A\n",
    "유니버설픽쳐스인터내셔널 코리아(유), B\n",
    "유한회사 엠프로젝트, D\n",
    "주식회사 블루필름웍스, D\n",
    "주식회사 에이비오엔터테인먼트, D\n",
    "주식회사 에이투지엔터테인먼트, D\n",
    "주식회사 올랄라스토리, D\n",
    "주식회사 왓챠, C\n",
    "주식회사 필름영, C\n",
    "찬란, C\n",
    "트윈플러스파트너스(주), D\n",
    "판씨네마(주), B\n",
    "플러스엠 엔터테인먼트, A\n",
    "홀리가든, D\"\"\"\n",
    "\n",
    "# 빈 리스트 초기화\n",
    "distributors_list = []\n",
    "grades_list = []\n",
    "\n",
    "# 데이터를 줄 단위로 나누기\n",
    "lines = data.strip().split('\\n')\n",
    "for line in lines:\n",
    "    distributor, grade = line.strip().rsplit(',', 1)\n",
    "    distributors_list.append(distributor.strip())\n",
    "    grades_list.append(grade.strip())\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({\n",
    "    'Distributor': distributors_list,\n",
    "    '평가': grades_list\n",
    "})\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "output_csv_file_path = 'distributors.csv'\n",
    "df.to_csv(output_csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Distributor와 평가 컬럼이 포함된 CSV 파일이 {output_csv_file_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a854108-c0b8-486e-96e1-0b54c863bf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributor_Sc 컬럼이 포함된 CSV 파일이 preprosessing_ver3.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "movies_csv_path = '0530_dataset\\preprosessing_ver2.csv'\n",
    "distributors_csv_path = '0530_dataset\\distributors.csv'\n",
    "output_csv_path = 'preprosessing_ver3.csv'\n",
    "\n",
    "# 영화 데이터와 배급사 평가 데이터를 읽기\n",
    "movies_df = pd.read_csv(movies_csv_path)\n",
    "distributors_df = pd.read_csv(distributors_csv_path)\n",
    "\n",
    "# 배급사 평가 데이터를 딕셔너리로 변환\n",
    "distributor_grades = dict(zip(distributors_df['Distributor'], distributors_df['평가']))\n",
    "\n",
    "def evaluate_distributors(distributor_str, grades_dict):\n",
    "    # 배급사 문자열을 분리\n",
    "    distributors = [d.strip() for d in distributor_str.split(',')]\n",
    "    # 배급사 등급 리스트 생성\n",
    "    grades = [grades_dict.get(d, 'D') for d in distributors]\n",
    "    \n",
    "    # 평가 기준 적용\n",
    "    if 'A' in grades:\n",
    "        return 'A'\n",
    "    elif 'B' in grades:\n",
    "        return 'B'\n",
    "    elif 'C' in grades:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "# Distributor_Sc 컬럼 추가\n",
    "movies_df['Distributor_Sc'] = movies_df['Distributor'].apply(evaluate_distributors, grades_dict=distributor_grades)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "movies_df.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Distributor_Sc 컬럼이 포함된 CSV 파일이 {output_csv_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8e1cf5-cab8-484a-8e61-3926689b47a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감독 이름이 비어 있는 영화 제목:\n",
      "['슈퍼 마리오 브라더스', '던전 앤 드래곤: 도적들의 명예', '그란 투리스모', '말하고 싶은 비밀', '아기상어 극장판: 사이렌 스톤의 비밀', '극장판 도라에몽: 진구와 하늘의 유토피아', '아이유 콘서트 : 더 골든 아워', '바다 탐험대 옥토넛 어보브 앤 비욘드 : 육지 넘어 하늘까지!', '바다 탐험대 옥토넛 : 탐험선 대작전', '유미의 세포들 더 무비', '바다 탐험대 옥토넛 어보브 앤 비욘드: 버드, 옥토경보를 울려라!', '이빨요정 비올레타: 요정나라로 돌아갈래!', '바다 탐험대 옥토넛 육지수호 대작전 : 열대우림을 지켜라!', '정글번치: 월드투어', '애프터썬', '비투비 타임 : 비투게더 더 무비', '테일러 스위프트 디 에라스 투어', '돌핀보이', '너는 내 아들', '이승윤 콘서트 도킹 : 리프트오프', '루이스 웨인: 사랑을 그린 고양이 화가', '극장판 바다 탐험대 옥토넛 : 해저동굴 대탈출']\n",
      "배우가 비어 있는 영화 제목:\n",
      "['엘리멘탈', '더 퍼스트 슬램덩크', '건국전쟁', '신차원! 짱구는 못말려 더 무비 초능력 대결전 ~날아라 수제김밥~', '극장판 짱구는 못말려: 수수께끼! 꽃피는 천하떡잎학교', '명탐정코난: 흑철의 어영', '극장판 짱구는 못말려: 동물소환 닌자 배꼽수비대', '귀멸의 칼날: 인연의 기적, 그리고 합동 강화 훈련으로', '명탐정 코난: 할로윈의 신부', '원피스 필름 레드', '톡 투 미', '포켓몬스터: 성도지방 이야기, 최종장', '눈의 여왕5: 스노우 프린세스와 미러랜드의 비밀', '두다다쿵: 후후섬의 비밀', '그란 투리스모', '문재인입니다', '사나: 저주의 아이', '바다 탐험대 옥토넛 어보브 앤 비욘드: 버드, 옥토경보를 울려라!', '크레센도', '이빨요정 비올레타: 요정나라로 돌아갈래!', '런닝맨: 리벤져스', '마야 3: 숲속 왕국의 위기', '정글번치: 월드투어', '아인보: 아마존의 전설', '마브카 : 숲의 노래', '로봇 드림', '2022 영탁 단독 콘서트 \"탁쇼\"', '틴에이지 크라켄 루비', '엔드 오브 에반게리온', '비투비 타임 : 비투게더 더 무비', '테일러 스위프트 디 에라스 투어', '사랑은 낙엽을 타고', '너는 내 아들', '이승윤 콘서트 도킹 : 리프트오프', '극장판 엉덩이 탐정: 수플레 섬의 비밀', '나의 히어로 아카데미아 더 무비: 월드 히어로즈 미션']\n",
      "감독 이름과 배우가 둘 다 비어 있는 영화 제목:\n",
      "['그란 투리스모', '바다 탐험대 옥토넛 어보브 앤 비욘드: 버드, 옥토경보를 울려라!', '이빨요정 비올레타: 요정나라로 돌아갈래!', '정글번치: 월드투어', '비투비 타임 : 비투게더 더 무비', '테일러 스위프트 디 에라스 투어', '너는 내 아들', '이승윤 콘서트 도킹 : 리프트오프']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "movies_csv_path = '0530_dataset/preprosessing_ver3.csv'\n",
    "\n",
    "# 영화 데이터 읽기\n",
    "movies_df = pd.read_csv(movies_csv_path)\n",
    "\n",
    "# 감독 이름과 배우가 비어 있는 행 필터링\n",
    "empty_director_movies = movies_df[movies_df['Director'].isna() | (movies_df['Director'].str.strip() == '')]\n",
    "empty_actors_movies = movies_df[movies_df['Actors'].isna() | (movies_df['Actors'].str.strip() == '')]\n",
    "\n",
    "# 둘 다 비어 있는 행 필터링\n",
    "empty_both_movies = movies_df[(movies_df['Director'].isna() | (movies_df['Director'].str.strip() == '')) &\n",
    "                              (movies_df['Actors'].isna() | (movies_df['Actors'].str.strip() == ''))]\n",
    "\n",
    "# 감독 이름이 비어 있는 영화 제목\n",
    "print(\"감독 이름이 비어 있는 영화 제목:\")\n",
    "print(empty_director_movies['Movie_Title'].tolist())\n",
    "\n",
    "# 배우가 비어 있는 영화 제목\n",
    "print(\"배우가 비어 있는 영화 제목:\")\n",
    "print(empty_actors_movies['Movie_Title'].tolist())\n",
    "\n",
    "# 감독 이름과 배우가 둘 다 비어 있는 영화 제목\n",
    "print(\"감독 이름과 배우가 둘 다 비어 있는 영화 제목:\")\n",
    "print(empty_both_movies['Movie_Title'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e7494a-e6e2-4818-9bd5-cd9885a0dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Movie_Title          Director  \\\n",
      "7                                    엘리멘탈              피터 손   \n",
      "11                             더 퍼스트 슬램덩크         이노우에 다케히코   \n",
      "24                            슈퍼 마리오 브라더스               NaN   \n",
      "47                                   건국전쟁               김덕영   \n",
      "53   신차원! 짱구는 못말려 더 무비 초능력 대결전 ~날아라 수제김밥~            오네 히토시   \n",
      "59          극장판 짱구는 못말려: 수수께끼! 꽃피는 천하떡잎학교          타카하시 와타루   \n",
      "61                          명탐정코난: 흑철의 어영          타치카와 유즈루   \n",
      "66             극장판 짱구는 못말려: 동물소환 닌자 배꼽수비대         하시모토 마사카즈   \n",
      "83         귀멸의 칼날: 인연의 기적, 그리고 합동 강화 훈련으로          소토자키 하루오   \n",
      "84                        명탐정 코난: 할로윈의 신부          미츠나카 스스무   \n",
      "110                     던전 앤 드래곤: 도적들의 명예               NaN   \n",
      "127                             원피스 필름 레드           타니구치 고로   \n",
      "131                                 톡 투 미    대니 필리푸,마이클 필리푸   \n",
      "139                  포켓몬스터: 성도지방 이야기, 최종장          유야마 쿠니히코   \n",
      "141            눈의 여왕5: 스노우 프린세스와 미러랜드의 비밀         알렉세이 트시칠린   \n",
      "147                         두다다쿵: 후후섬의 비밀           최병선,김지윤   \n",
      "149                               그란 투리스모               NaN   \n",
      "152                             말하고 싶은 비밀               NaN   \n",
      "153                                문재인입니다               이창재   \n",
      "161                  아기상어 극장판: 사이렌 스톤의 비밀               NaN   \n",
      "167                극장판 도라에몽: 진구와 하늘의 유토피아               NaN   \n",
      "171                     아이유 콘서트 : 더 골든 아워               NaN   \n",
      "172    바다 탐험대 옥토넛 어보브 앤 비욘드 : 육지 넘어 하늘까지!               NaN   \n",
      "173                            사나: 저주의 아이           시미즈 다카시   \n",
      "177                  바다 탐험대 옥토넛 : 탐험선 대작전               NaN   \n",
      "179                          유미의 세포들 더 무비               NaN   \n",
      "183  바다 탐험대 옥토넛 어보브 앤 비욘드: 버드, 옥토경보를 울려라!               NaN   \n",
      "184                                  크레센도             헤더 윌크   \n",
      "194                이빨요정 비올레타: 요정나라로 돌아갈래!               NaN   \n",
      "196      바다 탐험대 옥토넛 육지수호 대작전 : 열대우림을 지켜라!               NaN   \n",
      "203                             런닝맨: 리벤져스               엄영식   \n",
      "205                       마야 3: 숲속 왕국의 위기           노엘 클리어리   \n",
      "208                            정글번치: 월드투어               NaN   \n",
      "209                          아인보: 아마존의 전설   리처드 클라우스,호세 젤라다   \n",
      "210                           마브카 : 숲의 노래             올레말라므   \n",
      "214                                  애프터썬               NaN   \n",
      "217                                 로봇 드림          파블로 베르헤르   \n",
      "222                   2022 영탁 단독 콘서트 \"탁쇼\"               송승연   \n",
      "227                           틴에이지 크라켄 루비           커크 드 미코   \n",
      "237                           엔드 오브 에반게리온  안노 히데아키,츠루마키 카즈야   \n",
      "239                    비투비 타임 : 비투게더 더 무비               NaN   \n",
      "241                     테일러 스위프트 디 에라스 투어               NaN   \n",
      "244                            사랑은 낙엽을 타고         아키 카우리스마키   \n",
      "251                                  돌핀보이               NaN   \n",
      "259                               너는 내 아들               NaN   \n",
      "261                    이승윤 콘서트 도킹 : 리프트오프               NaN   \n",
      "282                 극장판 엉덩이 탐정: 수플레 섬의 비밀           자코 아키후미   \n",
      "293         나의 히어로 아카데미아 더 무비: 월드 히어로즈 미션           나가사키 켄지   \n",
      "294                 루이스 웨인: 사랑을 그린 고양이 화가               NaN   \n",
      "298             극장판 바다 탐험대 옥토넛 : 해저동굴 대탈출               NaN   \n",
      "\n",
      "                                                Actors  \n",
      "7                                                  NaN  \n",
      "11                                                 NaN  \n",
      "24                         크리스 프랫,안야 테일러 조이,잭 블랙,찰리 데이  \n",
      "47                                                 NaN  \n",
      "53                                                 NaN  \n",
      "59                                                 NaN  \n",
      "61                                                 NaN  \n",
      "66                                                 NaN  \n",
      "83                                                 NaN  \n",
      "84                                                 NaN  \n",
      "110    크리스 파인,미셸 로드리게즈,레게-장 페이지,저스티스 스미스,소피아 릴리스,휴 그랜트  \n",
      "127                                                NaN  \n",
      "131                                                NaN  \n",
      "139                                                NaN  \n",
      "141                                                NaN  \n",
      "147                                                NaN  \n",
      "149                                                NaN  \n",
      "152                                           사쿠라다 히요리  \n",
      "153                                                NaN  \n",
      "161  장예나,전태열,이희승(엔하이픈),박종성(엔하이픈),심재윤(엔하이픈),박성훈(엔하이픈...  \n",
      "167                                윤아영,김정아,이현주,조현정,최낙윤  \n",
      "171                                                이지은  \n",
      "172                 하성용,정재헌,엄상현,윤승희,김율,유동균,김정은,한경화,박성영  \n",
      "173                                                NaN  \n",
      "177                     하성용,정재헌,엄상현,윤승희,김율,유동균,김정은,한경화  \n",
      "179                            윤아영,신범식,송하림,안소이,사문영,안영미  \n",
      "183                                                NaN  \n",
      "184                                                NaN  \n",
      "194                                                NaN  \n",
      "196             하성용,정재헌,엄상현,윤승희,김율,유동균,김정은,한경화,박성영,이재현  \n",
      "203                                                NaN  \n",
      "205                                                NaN  \n",
      "208                                                NaN  \n",
      "209                                                NaN  \n",
      "210                                                NaN  \n",
      "214                                              폴 메스칼  \n",
      "217                                                NaN  \n",
      "222                                                NaN  \n",
      "227                                                NaN  \n",
      "237                                                NaN  \n",
      "239                                                NaN  \n",
      "241                                                NaN  \n",
      "244                                                NaN  \n",
      "251                                                박시윤  \n",
      "259                                                NaN  \n",
      "261                                                NaN  \n",
      "282                                                NaN  \n",
      "293                                                NaN  \n",
      "294  베네딕트 컴버배치,클레어 포이,올리비아 콜맨,토비 존스,안드레아 라이즈보로,스테이시...  \n",
      "298                  하성용,정재헌,엄상현,윤승희,김율,유동균,김정은,한경화,장미  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "movies_csv_path = '0530_dataset/preprosessing_ver3.csv'\n",
    "\n",
    "# 영화 데이터 읽기\n",
    "movies_df = pd.read_csv(movies_csv_path)\n",
    "\n",
    "# 감독 이름 또는 배우가 비어 있는 행 필터링\n",
    "empty_director_or_actors_movies = movies_df[movies_df['Director'].isna() | (movies_df['Director'].str.strip() == '') |\n",
    "                                            movies_df['Actors'].isna() | (movies_df['Actors'].str.strip() == '')]\n",
    "\n",
    "# 감독 이름 또는 배우가 비어 있는 행 삭제\n",
    "cleaned_movies_df = movies_df.drop(empty_director_or_actors_movies.index)\n",
    "\n",
    "# 삭제된 행 정보\n",
    "deleted_movies = empty_director_or_actors_movies[['Movie_Title', 'Director', 'Actors']]\n",
    "\n",
    "print(deleted_movies)\n",
    "# 저장된 데이터를 새로운 CSV 파일로 저장 (원본 데이터를 덮어쓰지 않기 위해 경로 변경)\n",
    "cleaned_movies_csv_path = 'cleaned_preprosessing_ver3.csv'\n",
    "cleaned_movies_df.to_csv(cleaned_movies_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7622b8e8-3834-484a-9634-98fa8065c8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Movie_Title     w1_av_sc     w2_av_sc     w3_av_sc\n",
      "0         서울의 봄  1062.717386  1189.735052  1074.807535\n",
      "1            파묘  1560.289309  1501.112580   898.330183\n",
      "2         범죄도시4  1735.738878  1370.078330   606.151817\n",
      "3     아바타: 물의 길  1154.896109  1265.188198   974.919402\n",
      "4         범죄도시3  2527.987292   951.132874   741.933813\n",
      "..          ...          ...          ...          ...\n",
      "247    나이트메어 앨리    68.311025    51.121013    59.029851\n",
      "248     어나더 라운드    88.648438   172.478261   133.559229\n",
      "249         시라노   106.430614    26.863158    43.633333\n",
      "250     리코리쉬 피자    65.677918    43.432308    48.137441\n",
      "251      우연과 상상   205.234463   106.270950    80.111111\n",
      "\n",
      "[252 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'updated_file.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Update w2_au and w3_au for all rows\n",
    "df['w1_av_sc'] = df['w1_au'] / df['w1_av_sc']\n",
    "df['w2_av_sc'] = df['w2_au'] / df['w2_av_sc']\n",
    "df['w3_av_sc'] = df['w3_au'] / df['w3_av_sc']\n",
    "\n",
    "# 업데이트된 데이터프레임을 확인합니다\n",
    "print(df[['Movie_Title', 'w1_av_sc', 'w2_av_sc', 'w3_av_sc']])\n",
    "\n",
    "# 변경된 내용을 새로운 CSV 파일로 저장합니다\n",
    "df.to_csv('updated_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "991cba20-5dd6-4c8d-9633-ac124d0f1433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       w1_au    w2_au     w1_av_sc     w2_av_sc\n",
      "0    2364698  2703248  1062.717386  1189.735052\n",
      "1    3312940  3293441  1560.289309  1501.112580\n",
      "2    5005375  3713108  1735.738878  1370.078330\n",
      "3    3201537  2814863  1154.896109  1265.188198\n",
      "4    6053085  1993031  2527.987292   951.132874\n",
      "..       ...      ...          ...          ...\n",
      "247    27705     7785    68.311025    51.121013\n",
      "248    14589     7934    88.648438   172.478261\n",
      "249    18078     2552   106.430614    26.863158\n",
      "250    13342     4033    65.677918    43.432308\n",
      "251    10379     5435   205.234463   106.270950\n",
      "\n",
      "[252 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'updated_file.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 필요한 컬럼만 추출\n",
    "selected_columns = df[['w1_au', 'w2_au', 'w1_av_sc', 'w2_av_sc']]\n",
    "\n",
    "# 추출한 데이터프레임을 확인합니다\n",
    "print(selected_columns)\n",
    "\n",
    "# 추출한 내용을 새로운 CSV 파일로 저장합니다\n",
    "selected_columns.to_csv('selected_columns.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae2b520-ba93-4954-aa91-37d949d57aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          NaN         1         2                  3                   4  \\\n",
      "0        서울의 봄  55.50419  73.67073           79.25816   71.19690682872215   \n",
      "1           파묘  67.49954  82.78116  75.60018635864003   84.74670131624185   \n",
      "2        범죄도시4     100.0  84.14176           70.42814    31.6227952530688   \n",
      "3    아바타: 물의 길  84.31055  82.30668           81.87475   75.60018635864003   \n",
      "4        범죄도시3  95.40589   93.4583           83.45108   75.60018635864003   \n",
      "..         ...       ...       ...                ...                 ...   \n",
      "247   나이트메어 앨리  82.97027  75.13949           76.48352   75.60018635864003   \n",
      "248    어나더 라운드  72.34199  74.63083           89.75191   75.60018635864003   \n",
      "249        시라노     100.0   94.2359           92.18332   69.12874743020433   \n",
      "250    리코리쉬 피자  93.22194   84.3693           85.79459   75.60018635864003   \n",
      "251     우연과 상상  66.60961     100.0           92.80358  37.830231116100606   \n",
      "\n",
      "0                    5         6         7  \n",
      "0    91.71449075599527  88.93493  72.35861  \n",
      "1             78.13019  54.66054  51.43671  \n",
      "2     46.6069551919917  50.76426  42.00864  \n",
      "3    68.31440624890186  57.97047  53.22427  \n",
      "4    87.46481854289252  75.90528  73.95812  \n",
      "..                 ...       ...       ...  \n",
      "247  81.09143155197474  70.44479  55.09979  \n",
      "248  63.45658098640107  64.11695  56.34967  \n",
      "249  67.91814340626563  63.82679  56.36159  \n",
      "250  80.47638683253291  68.49315  62.11101  \n",
      "251  52.97137155301878  66.71556  56.38141  \n",
      "\n",
      "[252 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = '0530_dataset\\combined_trend_data_adjusted.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# 'period' 행 제거\n",
    "df = df[df[0] != 'period']\n",
    "\n",
    "# 컬럼명을 첫 번째 행으로 설정\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "\n",
    "# 인덱스를 새로 설정\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 업데이트된 데이터프레임을 확인합니다\n",
    "print(df)\n",
    "\n",
    "# 변경된 내용을 새로운 CSV 파일로 저장합니다\n",
    "df.to_csv('updated_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406a377f-ad2f-4f5c-a3c0-7b12c63a420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0          1          2          3          4          5  \\\n",
      "0        서울의 봄   55.50419   73.67073  79.258160  71.196907  91.714491   \n",
      "1           파묘   67.49954   82.78116  75.600186  84.746701  78.130190   \n",
      "2        범죄도시4  100.00000   84.14176  70.428140  31.622795  46.606955   \n",
      "3    아바타: 물의 길   84.31055   82.30668  81.874750  75.600186  68.314406   \n",
      "4        범죄도시3   95.40589   93.45830  83.451080  75.600186  87.464819   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "247   나이트메어 앨리   82.97027   75.13949  76.483520  75.600186  81.091432   \n",
      "248    어나더 라운드   72.34199   74.63083  89.751910  75.600186  63.456581   \n",
      "249        시라노  100.00000   94.23590  92.183320  69.128747  67.918143   \n",
      "250    리코리쉬 피자   93.22194   84.36930  85.794590  75.600186  80.476387   \n",
      "251     우연과 상상   66.60961  100.00000  92.803580  37.830231  52.971372   \n",
      "\n",
      "            6         7     slope  \n",
      "0    88.93493  72.35861  0.092267  \n",
      "1    54.66054  51.43671 -0.109255  \n",
      "2    50.76426  42.00864 -0.138178  \n",
      "3    57.97047  53.22427 -0.178641  \n",
      "4    75.90528  73.95812 -0.158917  \n",
      "..        ...       ...       ...  \n",
      "247  70.44479  55.09979 -0.113270  \n",
      "248  64.11695  56.34967 -0.101897  \n",
      "249  63.82679  56.36159 -0.176776  \n",
      "250  68.49315  62.11101 -0.149699  \n",
      "251  66.71556  56.38141 -0.078751  \n",
      "\n",
      "[252 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'trend_data_ver1.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 정규화 함수\n",
    "def normalize(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "# 단순선형회귀를 계산하는 함수\n",
    "def linear_regression_slope(x, y):\n",
    "    n = len(x)\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    numerator = np.sum((x - x_mean) * (y - y_mean))\n",
    "    denominator = np.sum((x - x_mean) ** 2)\n",
    "    slope = numerator / denominator\n",
    "    return slope\n",
    "\n",
    "# 각 행에 대해 정규화 및 회귀 기울기 계산\n",
    "slopes = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # 1~7번 컬럼 선택 및 정규화\n",
    "    data = row[1:8].astype(float)\n",
    "    normalized_data = normalize(data)\n",
    "    \n",
    "    # 단순선형회귀 수행\n",
    "    X = np.arange(len(normalized_data))\n",
    "    y = normalized_data.values\n",
    "    slope = linear_regression_slope(X, y)\n",
    "    \n",
    "    # 기울기를 리스트에 추가\n",
    "    slopes.append(slope)\n",
    "\n",
    "# 새로운 컬럼으로 기울기 추가\n",
    "df['slope'] = slopes\n",
    "\n",
    "# 결과 출력\n",
    "print(df)\n",
    "\n",
    "# 변경된 내용을 새로운 CSV 파일로 저장합니다\n",
    "df.to_csv('updated_file_with_slopes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fb3640-fd14-4b4e-9f6b-79fe7bf544c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       w1_au    w2_au     w1_av_sc     slope\n",
      "0    2364698  2703248  1062.717386  0.092267\n",
      "1    3312940  3293441  1560.289309 -0.109255\n",
      "2    5005375  3713108  1735.738878 -0.138178\n",
      "3    3201537  2814863  1154.896109 -0.178641\n",
      "4    6053085  1993031  2527.987292 -0.158917\n",
      "..       ...      ...          ...       ...\n",
      "247    27705     7785    68.311025 -0.113270\n",
      "248    14589     7934    88.648438 -0.101897\n",
      "249    18078     2552   106.430614 -0.176776\n",
      "250    13342     4033    65.677918 -0.149699\n",
      "251    10379     5435   205.234463 -0.078751\n",
      "\n",
      "[252 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 두 개의 CSV 파일 읽기\n",
    "trend_data_file = 'trend_data_ver2.csv'  # 'slope' 열이 있는 파일\n",
    "selected_columns_file = 'selected_columns.csv'  # 새로 'slope' 열을 추가할 파일\n",
    "\n",
    "# 파일 읽기\n",
    "trend_data_df = pd.read_csv(trend_data_file)\n",
    "selected_columns_df = pd.read_csv(selected_columns_file)\n",
    "\n",
    "# 'slope' 열 추가\n",
    "selected_columns_df['slope'] = trend_data_df['slope']\n",
    "selected_columns_df.drop(\"w2_av_sc\",axis=1,inplace=True)\n",
    "# 결과 확인\n",
    "print(selected_columns_df)\n",
    "\n",
    "# 변경된 내용을 새로운 CSV 파일로 저장합니다\n",
    "selected_columns_df.to_csv('updated_selected_columns.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb97573-f49c-4d1b-a9b8-c55f5e86e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'updated_selected_columns.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 상관 관계 매트릭스 생성\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# 상관 관계 매트릭스 출력\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e5ff88-7708-4e5d-899e-860ec58a8d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances: [0.83691205 0.1206459  0.04244205]\n",
      "Selected Features: Index(['w1_au'], dtype='object')\n",
      "Training MSE: 9754050271.1377\n",
      "Test MSE: 61544063892.6920\n",
      "Training RMSE: 98762.5955\n",
      "Test RMSE: 248080.7608\n",
      "Training R^2: 0.9669\n",
      "Test R^2: 0.6448\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'updated_selected_columns.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 독립 변수와 종속 변수 설정\n",
    "X = df[['w1_au', 'w1_av_sc', 'slope']]\n",
    "y = df['w2_au']\n",
    "\n",
    "# 데이터 분할 (훈련 세트와 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링 (정규화)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 랜덤 포레스트 모델 학습\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 피처 중요도 출력\n",
    "feature_importances = rf.feature_importances_\n",
    "print('Feature Importances:', feature_importances)\n",
    "\n",
    "# 피처 중요도를 기반으로 피처 선택\n",
    "selector = SelectFromModel(rf, prefit=True, threshold='mean')\n",
    "X_train_selected = selector.transform(X_train_scaled)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# 선택된 피처 확인\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print('Selected Features:', selected_features)\n",
    "\n",
    "# 선택된 피처로 모델 재학습 및 평가\n",
    "rf_selected = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_selected.fit(X_train_selected, y_train)\n",
    "y_pred_train = rf_selected.predict(X_train_selected)\n",
    "y_pred_test = rf_selected.predict(X_test_selected)\n",
    "\n",
    "# 모델 평가\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f'Training MSE: {mse_train:.4f}')\n",
    "print(f'Test MSE: {mse_test:.4f}')\n",
    "print(f'Training RMSE: {rmse_train:.4f}')\n",
    "print(f'Test RMSE: {rmse_test:.4f}')\n",
    "print(f'Training R^2: {r2_train:.4f}')\n",
    "print(f'Test R^2: {r2_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecba9ec8-ebc2-475c-90b9-8f5ed2a4a5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 10982193196.0591\n",
      "Test MSE: 40232469462.0445\n",
      "Training RMSE: 104795.9598\n",
      "Test RMSE: 200580.3317\n",
      "Training R^2: 0.9628\n",
      "Test R^2: 0.7678\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'updated_selected_columns.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 독립 변수와 종속 변수 설정\n",
    "X = df[['w1_au', 'w1_av_sc', 'slope']]\n",
    "y = df['w2_au']\n",
    "\n",
    "# 데이터 분할 (훈련 세트와 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링 (정규화)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 랜덤 포레스트 모델 학습\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 모든 피처를 사용한 모델 학습 및 평가\n",
    "y_pred_train = rf.predict(X_train_scaled)\n",
    "y_pred_test = rf.predict(X_test_scaled)\n",
    "\n",
    "# 모델 평가\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f'Training MSE: {mse_train:.4f}')\n",
    "print(f'Test MSE: {mse_test:.4f}')\n",
    "print(f'Training RMSE: {rmse_train:.4f}')\n",
    "print(f'Test RMSE: {rmse_test:.4f}')\n",
    "print(f'Training R^2: {r2_train:.4f}')\n",
    "print(f'Test R^2: {r2_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e959d30d-e497-4b5b-bcbb-9fe2fd129f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation MSE Scores: [4.10147892e+10 5.74722939e+10 9.01000930e+10 4.49072684e+10\n",
      " 7.36621168e+10]\n",
      "Mean Cross-Validation MSE: 61431312264.058044\n",
      "Standard Deviation of Cross-Validation MSE: 18314168486.608395\n",
      "Overall MSE: 30767643645.4999\n",
      "Overall RMSE: 175407.0798\n",
      "Overall R^2: 0.8862\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'updated_selected_columns.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 독립 변수와 종속 변수 설정\n",
    "X = df[['w1_au', 'w1_av_sc', 'slope']]\n",
    "y = df['w2_au']\n",
    "\n",
    "# 데이터 스케일링 (정규화)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 랜덤 포레스트 모델 설정 (하이퍼파라미터 조정 포함)\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=10, random_state=42)\n",
    "\n",
    "# MSE 스코어링 함수\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# K-폴드 교차 검증 설정 (예: K=5)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 교차 검증 수행\n",
    "cv_scores = cross_val_score(rf, X_scaled, y, cv=kf, scoring=mse_scorer)\n",
    "\n",
    "# 교차 검증 결과 출력\n",
    "print(f'Cross-Validation MSE Scores: {-cv_scores}')\n",
    "print(f'Mean Cross-Validation MSE: {-np.mean(cv_scores)}')\n",
    "print(f'Standard Deviation of Cross-Validation MSE: {np.std(cv_scores)}')\n",
    "\n",
    "# 교차 검증 후 모델 학습 및 평가\n",
    "rf.fit(X_scaled, y)\n",
    "y_pred = rf.predict(X_scaled)\n",
    "\n",
    "# 모델 평가\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(f'Overall MSE: {mse:.4f}')\n",
    "print(f'Overall RMSE: {rmse:.4f}')\n",
    "print(f'Overall R^2: {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e903f550-eff0-401c-a2fb-fcf666963b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

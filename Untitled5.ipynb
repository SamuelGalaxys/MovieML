{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5bededf-4811-4079-9bdd-6276c8de7c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'multiTimeline (1).csv'는 잘못된 형식의 파일입니다.\n",
      "            카테고리: 모든 카테고리\n",
      "일           서울의 봄: (대한민국)\n",
      "2023-11-22             41\n",
      "2023-11-23             52\n",
      "2023-11-24             59\n",
      "2023-11-25            100\n",
      "2023-11-26             87\n",
      "2023-11-27             71\n",
      "2023-11-28             63\n",
      "'multiTimeline (80).csv'는 잘못된 형식의 파일입니다.\n",
      "                            카테고리: 모든 카테고리\n",
      "일  극장판 포켓몬스터DP  기라티나와 하늘의 꽃다발 쉐이미: (대한민국)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def validate_csv_format(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        # 올바른 형식인지 확인\n",
    "        if df.shape[1] == 2 and df.columns[0] == '일' and df.columns[1] != '':\n",
    "            print(f\"'{file_path}'는 올바른 형식의 파일입니다.\")\n",
    "        else:\n",
    "            print(f\"'{file_path}'는 잘못된 형식의 파일입니다.\")\n",
    "            print(df)\n",
    "    except Exception as e:\n",
    "        print(f\"'{file_path}'를 처리하는 중 오류 발생: {e}\")\n",
    "\n",
    "# 파일 경로 지정\n",
    "file_path_1 = 'multiTimeline (1).csv'\n",
    "file_path_2 = 'multiTimeline (80).csv'\n",
    "\n",
    "# 파일 검증\n",
    "validate_csv_format(file_path_1)\n",
    "validate_csv_format(file_path_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3c032d-18f6-4764-a52a-1c5849f940df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'multiTimeline (1).csv'는 올바른 형식의 파일입니다.\n",
      "'multiTimeline (2).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (2).csv'\n",
      "'multiTimeline (3).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (3).csv'\n",
      "'multiTimeline (4).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (4).csv'\n",
      "'multiTimeline (5).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (5).csv'\n",
      "'multiTimeline (6).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (6).csv'\n",
      "'multiTimeline (7).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (7).csv'\n",
      "'multiTimeline (8).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (8).csv'\n",
      "'multiTimeline (9).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (9).csv'\n",
      "'multiTimeline (10).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (10).csv'\n",
      "'multiTimeline (11).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (11).csv'\n",
      "'multiTimeline (12).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (12).csv'\n",
      "'multiTimeline (13).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (13).csv'\n",
      "'multiTimeline (14).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (14).csv'\n",
      "'multiTimeline (15).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (15).csv'\n",
      "'multiTimeline (16).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (16).csv'\n",
      "'multiTimeline (17).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (17).csv'\n",
      "'multiTimeline (18).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (18).csv'\n",
      "'multiTimeline (19).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (19).csv'\n",
      "'multiTimeline (20).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (20).csv'\n",
      "'multiTimeline (21).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (21).csv'\n",
      "'multiTimeline (22).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (22).csv'\n",
      "'multiTimeline (23).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (23).csv'\n",
      "'multiTimeline (24).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (24).csv'\n",
      "'multiTimeline (25).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (25).csv'\n",
      "'multiTimeline (26).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (26).csv'\n",
      "'multiTimeline (27).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (27).csv'\n",
      "'multiTimeline (28).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (28).csv'\n",
      "'multiTimeline (29).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (29).csv'\n",
      "'multiTimeline (30).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (30).csv'\n",
      "'multiTimeline (31).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (31).csv'\n",
      "'multiTimeline (32).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (32).csv'\n",
      "'multiTimeline (33).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (33).csv'\n",
      "'multiTimeline (34).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (34).csv'\n",
      "'multiTimeline (35).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (35).csv'\n",
      "'multiTimeline (36).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (36).csv'\n",
      "'multiTimeline (37).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (37).csv'\n",
      "'multiTimeline (38).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (38).csv'\n",
      "'multiTimeline (39).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (39).csv'\n",
      "'multiTimeline (40).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (40).csv'\n",
      "'multiTimeline (41).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (41).csv'\n",
      "'multiTimeline (42).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (42).csv'\n",
      "'multiTimeline (43).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (43).csv'\n",
      "'multiTimeline (44).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (44).csv'\n",
      "'multiTimeline (45).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (45).csv'\n",
      "'multiTimeline (46).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (46).csv'\n",
      "'multiTimeline (47).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (47).csv'\n",
      "'multiTimeline (48).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (48).csv'\n",
      "'multiTimeline (49).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (49).csv'\n",
      "'multiTimeline (50).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (50).csv'\n",
      "'multiTimeline (51).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (51).csv'\n",
      "'multiTimeline (52).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (52).csv'\n",
      "'multiTimeline (53).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (53).csv'\n",
      "'multiTimeline (54).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (54).csv'\n",
      "'multiTimeline (55).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (55).csv'\n",
      "'multiTimeline (56).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (56).csv'\n",
      "'multiTimeline (57).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (57).csv'\n",
      "'multiTimeline (58).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (58).csv'\n",
      "'multiTimeline (59).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (59).csv'\n",
      "'multiTimeline (60).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (60).csv'\n",
      "'multiTimeline (61).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (61).csv'\n",
      "'multiTimeline (62).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (62).csv'\n",
      "'multiTimeline (63).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (63).csv'\n",
      "'multiTimeline (64).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (64).csv'\n",
      "'multiTimeline (65).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (65).csv'\n",
      "'multiTimeline (66).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (66).csv'\n",
      "'multiTimeline (67).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (67).csv'\n",
      "'multiTimeline (68).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (68).csv'\n",
      "'multiTimeline (69).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (69).csv'\n",
      "'multiTimeline (70).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (70).csv'\n",
      "'multiTimeline (71).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (71).csv'\n",
      "'multiTimeline (72).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (72).csv'\n",
      "'multiTimeline (73).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (73).csv'\n",
      "'multiTimeline (74).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (74).csv'\n",
      "'multiTimeline (75).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (75).csv'\n",
      "'multiTimeline (76).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (76).csv'\n",
      "'multiTimeline (77).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (77).csv'\n",
      "'multiTimeline (78).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (78).csv'\n",
      "'multiTimeline (79).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (79).csv'\n",
      "'multiTimeline (80).csv'는 올바른 형식의 파일입니다.\n",
      "'multiTimeline (81).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (81).csv'\n",
      "'multiTimeline (82).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (82).csv'\n",
      "'multiTimeline (83).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (83).csv'\n",
      "'multiTimeline (84).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (84).csv'\n",
      "'multiTimeline (85).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (85).csv'\n",
      "'multiTimeline (86).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (86).csv'\n",
      "'multiTimeline (87).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (87).csv'\n",
      "'multiTimeline (88).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (88).csv'\n",
      "'multiTimeline (89).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (89).csv'\n",
      "'multiTimeline (90).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (90).csv'\n",
      "'multiTimeline (91).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (91).csv'\n",
      "'multiTimeline (92).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (92).csv'\n",
      "'multiTimeline (93).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (93).csv'\n",
      "'multiTimeline (94).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (94).csv'\n",
      "'multiTimeline (95).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (95).csv'\n",
      "'multiTimeline (96).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (96).csv'\n",
      "'multiTimeline (97).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (97).csv'\n",
      "'multiTimeline (98).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (98).csv'\n",
      "'multiTimeline (99).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (99).csv'\n",
      "'multiTimeline (100).csv'를 처리하는 중 오류 발생: [Errno 2] No such file or directory: 'multiTimeline (100).csv'\n",
      "['서울의 봄: (대한민국)', '극장판 포켓몬스터DP  기라티나와 하늘의 꽃다발 쉐이미: (대한민국)']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "valid_data = []\n",
    "invalid_data = []\n",
    "file_path_1=[f\"multiTimeline ({i}).csv\" for i in range(1,101)]\n",
    "\n",
    "for file_path in file_path_1:\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # 첫 번째 라인 삭제\n",
    "        lines = lines[1:]\n",
    "        \n",
    "        # 임시 파일로 저장하여 pandas로 읽기\n",
    "        with open('temp.csv', 'w', encoding='utf-8') as temp_file:\n",
    "            temp_file.writelines(lines)\n",
    "        \n",
    "        df = pd.read_csv('temp.csv')\n",
    "        \n",
    "        # 올바른 형식인지 확인\n",
    "        if df.shape[1] == 2 and df.columns[0] == '일' and df.columns[1] != '':\n",
    "            print(f\"'{file_path}'는 올바른 형식의 파일입니다.\")\n",
    "            valid_data.append(df.columns[1])\n",
    "        else:\n",
    "            print(f\"'{file_path}'는 잘못된 형식의 파일입니다.\")\n",
    "            invalid_data.append(df.columns[1])\n",
    "    except Exception as e:\n",
    "        print(f\"'{file_path}'를 처리하는 중 오류 발생: {e}\")\n",
    "\n",
    "print(valid_data)\n",
    "print(invalid_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1663fd5a-9c8f-4801-8169-94c765b39ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['서울의 봄: (대한민국)', '파묘: (대한민국)', '범죄도시4: (대한민국)', '아바타  물의 길: (대한민국)', '범죄도시3: (대한민국)', '탑건  매버릭: (대한민국)', '한산  용의 출현: (대한민국)', '엘리멘탈: (대한민국)', '공조 2: 인터내셔날: (대한민국)', '스즈메의 문단속: (대한민국)', '밀수: (대한민국)', '더 퍼스트 슬램덩크: (대한민국)', '노량  죽음의 바다: (대한민국)', '헌트: (대한민국)', '가디언즈 오브 갤럭시 VOL. 3: (대한민국)', '미션 임파서블 7: (대한민국)', '콘크리트 유토피아: (대한민국)', '웡카: (대한민국)', '올빼미: (대한민국)', '영웅: (대한민국)', '오펜하이머: (대한민국)', '쥬라기 월드  도미니언: (대한민국)', '토르  러브 앤 썬더: (대한민국)', '슈퍼 마리오 브라더스: (대한민국)', '미니언즈2: (대한민국)', '30일: (대한민국)', '블랙 팬서  와칸다 포에버: (대한민국)', '비상선언: (대한민국)', '그대들은 어떻게 살 것인가: (대한민국)', '듄  파트2: (대한민국)']\n",
      "30\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "valid_data = []\n",
    "invalid_data = []\n",
    "file_path_1=[f\"1~30//multiTimeline ({i}).csv\" for i in range(1,31)]\n",
    "\n",
    "for file_path in file_path_1:\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # 첫 번째 라인 삭제\n",
    "        lines = lines[1:]\n",
    "        \n",
    "        # 임시 파일로 저장하여 pandas로 읽기\n",
    "        with open('temp.csv', 'w', encoding='utf-8') as temp_file:\n",
    "            temp_file.writelines(lines)\n",
    "        \n",
    "        df = pd.read_csv('temp.csv')\n",
    "        \n",
    "        # 데이터프레임이 비어있는지 확인\n",
    "        if df.empty:\n",
    "            invalid_data.append(df.columns[1])\n",
    "        else:\n",
    "            valid_data.append(df.columns[1])\n",
    "    except Exception as e:\n",
    "        print(f\"'{file_path}'를 처리하는 중 오류 발생: {e}\")\n",
    "\n",
    "print(valid_data)\n",
    "print(len(valid_data))\n",
    "print(invalid_data)\n",
    "print(len(invalid_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db30d4b-47fc-47eb-b605-b165562fd420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['google_trend\\\\multiTimeline (1).csv', 'google_trend\\\\multiTimeline (10).csv', 'google_trend\\\\multiTimeline (11).csv', 'google_trend\\\\multiTimeline (12).csv', 'google_trend\\\\multiTimeline (13).csv', 'google_trend\\\\multiTimeline (14).csv', 'google_trend\\\\multiTimeline (15).csv', 'google_trend\\\\multiTimeline (16).csv', 'google_trend\\\\multiTimeline (17).csv', 'google_trend\\\\multiTimeline (18).csv', 'google_trend\\\\multiTimeline (19).csv', 'google_trend\\\\multiTimeline (2).csv', 'google_trend\\\\multiTimeline (20).csv', 'google_trend\\\\multiTimeline (21).csv', 'google_trend\\\\multiTimeline (22).csv', 'google_trend\\\\multiTimeline (23).csv', 'google_trend\\\\multiTimeline (24).csv', 'google_trend\\\\multiTimeline (25).csv', 'google_trend\\\\multiTimeline (26).csv', 'google_trend\\\\multiTimeline (27).csv', 'google_trend\\\\multiTimeline (28).csv', 'google_trend\\\\multiTimeline (3).csv', 'google_trend\\\\multiTimeline (30).csv', 'google_trend\\\\multiTimeline (31).csv', 'google_trend\\\\multiTimeline (35).csv', 'google_trend\\\\multiTimeline (36).csv', 'google_trend\\\\multiTimeline (37).csv', 'google_trend\\\\multiTimeline (38).csv', 'google_trend\\\\multiTimeline (39).csv', 'google_trend\\\\multiTimeline (4).csv', 'google_trend\\\\multiTimeline (42).csv', 'google_trend\\\\multiTimeline (44).csv', 'google_trend\\\\multiTimeline (46).csv', 'google_trend\\\\multiTimeline (47).csv', 'google_trend\\\\multiTimeline (48).csv', 'google_trend\\\\multiTimeline (49).csv', 'google_trend\\\\multiTimeline (5).csv', 'google_trend\\\\multiTimeline (50).csv', 'google_trend\\\\multiTimeline (51).csv', 'google_trend\\\\multiTimeline (52).csv', 'google_trend\\\\multiTimeline (53).csv', 'google_trend\\\\multiTimeline (55).csv', 'google_trend\\\\multiTimeline (56).csv', 'google_trend\\\\multiTimeline (57).csv', 'google_trend\\\\multiTimeline (59).csv', 'google_trend\\\\multiTimeline (6).csv', 'google_trend\\\\multiTimeline (61).csv', 'google_trend\\\\multiTimeline (62).csv', 'google_trend\\\\multiTimeline (63).csv', 'google_trend\\\\multiTimeline (64).csv', 'google_trend\\\\multiTimeline (65).csv', 'google_trend\\\\multiTimeline (66).csv', 'google_trend\\\\multiTimeline (67).csv', 'google_trend\\\\multiTimeline (68).csv', 'google_trend\\\\multiTimeline (7).csv', 'google_trend\\\\multiTimeline (70).csv', 'google_trend\\\\multiTimeline (71).csv', 'google_trend\\\\multiTimeline (72).csv', 'google_trend\\\\multiTimeline (73).csv', 'google_trend\\\\multiTimeline (74).csv', 'google_trend\\\\multiTimeline (75).csv', 'google_trend\\\\multiTimeline (76).csv', 'google_trend\\\\multiTimeline (77).csv', 'google_trend\\\\multiTimeline (78).csv', 'google_trend\\\\multiTimeline (79).csv', 'google_trend\\\\multiTimeline (8).csv', 'google_trend\\\\multiTimeline (81).csv', 'google_trend\\\\multiTimeline (82).csv', 'google_trend\\\\multiTimeline (83).csv', 'google_trend\\\\multiTimeline (84).csv', 'google_trend\\\\multiTimeline (85).csv', 'google_trend\\\\multiTimeline (86).csv', 'google_trend\\\\multiTimeline (87).csv', 'google_trend\\\\multiTimeline (88).csv', 'google_trend\\\\multiTimeline (89).csv', 'google_trend\\\\multiTimeline (9).csv', 'google_trend\\\\multiTimeline (90).csv', 'google_trend\\\\multiTimeline (91).csv', 'google_trend\\\\multiTimeline (92).csv', 'google_trend\\\\multiTimeline (94).csv', 'google_trend\\\\multiTimeline (95).csv', 'google_trend\\\\multiTimeline (96).csv', 'google_trend\\\\multiTimeline (97).csv', 'google_trend\\\\multiTimeline (98).csv', 'google_trend\\\\multiTimeline (99).csv', 'google_trend\\\\multiTimeline - 2024-05-29T080045.737.csv', 'google_trend\\\\multiTimeline - 2024-05-29T080209.528.csv', 'google_trend\\\\multiTimeline - 2024-05-29T080406.082.csv', 'google_trend\\\\multiTimeline - 2024-05-29T080541.819.csv', 'google_trend\\\\multiTimeline - 2024-05-29T080708.807.csv', 'google_trend\\\\multiTimeline - 2024-05-29T080826.575.csv', 'google_trend\\\\multiTimeline - 2024-05-29T080941.946.csv', 'google_trend\\\\multiTimeline - 2024-05-29T081109.408.csv', 'google_trend\\\\multiTimeline - 2024-05-29T081302.257.csv', 'google_trend\\\\multiTimeline - 2024-05-29T081427.097.csv', 'google_trend\\\\multiTimeline - 2024-05-29T081542.538.csv', 'google_trend\\\\multiTimeline - 2024-05-29T081707.025.csv', 'google_trend\\\\multiTimeline - 2024-05-29T081851.255.csv', 'google_trend\\\\multiTimeline - 2024-05-29T082047.767.csv', 'google_trend\\\\multiTimeline - 2024-05-29T082155.463.csv', 'google_trend\\\\multiTimeline - 2024-05-29T082433.457.csv', 'google_trend\\\\multiTimeline - 2024-05-29T082606.824.csv', 'google_trend\\\\multiTimeline - 2024-05-29T082736.814.csv', 'google_trend\\\\multiTimeline - 2024-05-29T082905.822.csv', 'google_trend\\\\multiTimeline - 2024-05-29T083049.880.csv', 'google_trend\\\\multiTimeline - 2024-05-29T083209.693.csv', 'google_trend\\\\multiTimeline - 2024-05-29T083500.618.csv', 'google_trend\\\\multiTimeline - 2024-05-29T083612.226.csv', 'google_trend\\\\multiTimeline - 2024-05-29T083901.483.csv', 'google_trend\\\\multiTimeline - 2024-05-29T084003.909.csv', 'google_trend\\\\multiTimeline - 2024-05-29T084110.945.csv', 'google_trend\\\\multiTimeline - 2024-05-29T084231.364.csv', 'google_trend\\\\multiTimeline - 2024-05-29T084519.614.csv', 'google_trend\\\\multiTimeline - 2024-05-29T084713.736.csv', 'google_trend\\\\multiTimeline - 2024-05-29T084843.764.csv', 'google_trend\\\\multiTimeline - 2024-05-29T085016.019.csv', 'google_trend\\\\multiTimeline - 2024-05-29T085305.516.csv', 'google_trend\\\\multiTimeline - 2024-05-29T085415.373.csv', 'google_trend\\\\multiTimeline - 2024-05-29T085732.919.csv', 'google_trend\\\\multiTimeline - 2024-05-29T085904.957.csv', 'google_trend\\\\multiTimeline - 2024-05-29T090825.418.csv', 'google_trend\\\\multiTimeline - 2024-05-29T091117.888.csv', 'google_trend\\\\multiTimeline - 2024-05-29T091238.129.csv', 'google_trend\\\\multiTimeline - 2024-05-29T091639.624.csv', 'google_trend\\\\multiTimeline - 2024-05-29T091947.671.csv', 'google_trend\\\\multiTimeline - 2024-05-29T092227.707.csv', 'google_trend\\\\multiTimeline - 2024-05-29T092441.914.csv', 'google_trend\\\\multiTimeline - 2024-05-29T092552.885.csv', 'google_trend\\\\multiTimeline - 2024-05-29T092737.359.csv', 'google_trend\\\\multiTimeline - 2024-05-29T093029.903.csv', 'google_trend\\\\multiTimeline - 2024-05-29T093148.824.csv', 'google_trend\\\\multiTimeline - 2024-05-29T093300.976.csv', 'google_trend\\\\multiTimeline - 2024-05-29T093608.337.csv', 'google_trend\\\\multiTimeline - 2024-05-29T093858.652.csv', 'google_trend\\\\multiTimeline - 2024-05-29T145408.617.csv']\n",
      "135\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m를 처리하는 중 오류 발생: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# 모든 시리즈를 하나의 데이터프레임으로 결합\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# 전치 후, 컬럼 이름들을 인덱스로 설정\u001b[39;00m\n\u001b[0;32m     91\u001b[0m transposed_df \u001b[38;5;241m=\u001b[39m combined_df\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "valid_data = []\n",
    "invalid_data = []\n",
    "series_list = []\n",
    "\n",
    "# 특정 폴더 내의 모든 csv 파일 경로 찾기\n",
    "file_path_1 = glob.glob(\"google_trend/*.csv\")\n",
    "\n",
    "for file_path in file_path_1:\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # 첫 번째 라인 삭제\n",
    "        lines = lines[1:]\n",
    "        \n",
    "        # 임시 파일로 저장하여 pandas로 읽기\n",
    "        with open('temp.csv', 'w', encoding='utf-8') as temp_file:\n",
    "            temp_file.writelines(lines)\n",
    "        \n",
    "        df = pd.read_csv('temp.csv')\n",
    "        \n",
    "        # 데이터프레임이 비어있는지 확인\n",
    "        if df.empty:\n",
    "            invalid_data.append(file_path)\n",
    "            os.remove(file_path)  # 파일 삭제\n",
    "        else:\n",
    "            series = pd.Series(df.iloc[:, 1].values, name=df.columns[1])\n",
    "            series_list.append(series)\n",
    "            valid_data.append(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"'{file_path}'를 처리하는 중 오류 발생: {e}\")\n",
    "\n",
    "# 모든 시리즈를 하나의 데이터프레임으로 결합\n",
    "combined_df = pd.concat(series_list, axis=1)\n",
    "\n",
    "# 전치 후, 컬럼 이름들을 인덱스로 설정\n",
    "transposed_df = combined_df.T\n",
    "transposed_df.index = combined_df.columns\n",
    "\n",
    "# CSV 파일로 저장\n",
    "transposed_df.to_csv('combined_data.csv', index=True)\n",
    "\n",
    "print(valid_data)\n",
    "print(len(valid_data))\n",
    "print(invalid_data)\n",
    "print(len(invalid_data))\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "valid_data = []\n",
    "invalid_data = []\n",
    "series_list = []\n",
    "\n",
    "# 특정 폴더 내의 모든 csv 파일 경로 찾기\n",
    "file_path_1 = glob.glob(\"path_to_folder/*.csv\")\n",
    "\n",
    "for file_path in file_path_1:\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # 첫 번째 라인 삭제\n",
    "        lines = lines[1:]\n",
    "        \n",
    "        # 임시 파일로 저장하여 pandas로 읽기\n",
    "        with open('temp.csv', 'w', encoding='utf-8') as temp_file:\n",
    "            temp_file.writelines(lines)\n",
    "        \n",
    "        df = pd.read_csv('temp.csv')\n",
    "        \n",
    "        # 데이터프레임이 비어있는지 확인\n",
    "        if df.empty:\n",
    "            invalid_data.append(file_path)\n",
    "            os.remove(file_path)  # 파일 삭제\n",
    "        else:\n",
    "            series = pd.Series(df.iloc[:, 1].values, name=df.columns[1])\n",
    "            series_list.append(series)\n",
    "            valid_data.append(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"'{file_path}'를 처리하는 중 오류 발생: {e}\")\n",
    "\n",
    "# 모든 시리즈를 하나의 데이터프레임으로 결합\n",
    "combined_df = pd.concat(series_list, axis=1)\n",
    "\n",
    "# 전치 후, 컬럼 이름들을 인덱스로 설정\n",
    "transposed_df = combined_df.T\n",
    "transposed_df.index = combined_df.columns\n",
    "\n",
    "# CSV 파일로 저장\n",
    "transposed_df.to_csv('combined_data.csv', index=True)\n",
    "\n",
    "print(valid_data)\n",
    "print(len(valid_data))\n",
    "print(invalid_data)\n",
    "print(len(invalid_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491decd7-4ada-4a46-bce1-ef17b8abf7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

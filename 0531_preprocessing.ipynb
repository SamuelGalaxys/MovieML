{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68792497-4f9b-4951-8040-55f214459241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributor 리스트가 distributors_list.txt 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "csv_file_path = '0530_dataset\\preprosessing_ver2.csv'\n",
    "output_txt_file_path = 'distributors_list.txt'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Distributor 컬럼에서 중복 제거한 값들을 리스트로 저장\n",
    "distributors = set()\n",
    "for distributors_str in df['Distributor']:\n",
    "    for distributor in distributors_str.split(','):\n",
    "        distributors.add(distributor.strip())\n",
    "\n",
    "# 텍스트 파일로 내보내기\n",
    "with open(output_txt_file_path, 'w') as file:\n",
    "    for distributor in sorted(distributors):\n",
    "        file.write(f\"{distributor}\\n\")\n",
    "\n",
    "print(f\"Distributor 리스트가 {output_txt_file_path} 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367473ff-8eb6-4c70-bbb6-285a8a6b443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributor와 평가 컬럼이 포함된 CSV 파일이 distributors.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 주어진 텍스트 데이터를 그대로 문자열로 저장\n",
    "data = \"\"\"(주)넥스트엔터테인먼트월드(NEW), A\n",
    "(주)누리픽쳐스, D\n",
    "(주)대교 미디어콘텐츠사업본부, D\n",
    "(주)디스테이션, C\n",
    "(주)라이크콘텐츠, D\n",
    "(주)레드아이스 엔터테인먼트, D\n",
    "(주)마인드마크, D\n",
    "(주)명필름, D\n",
    "(주)무비다이브, D\n",
    "(주)미디어캐슬, C\n",
    "(주)바른손이앤에이, D\n",
    "(주)바이포엠스튜디오, D\n",
    "(주)박수엔터테인먼트, C\n",
    "(주)버킷스튜디오, D\n",
    "(주)블루라벨픽쳐스, D\n",
    "(주)쇼박스, A\n",
    "(주)스마일이엔티, B\n",
    "(주)스튜디오 산타클로스엔터테인먼트, D\n",
    "(주)스튜디오디에이치엘, D\n",
    "(주)시네마6411, D\n",
    "(주)시네마달, D\n",
    "(주)싸이더스, B\n",
    "(주)씨네필운, D\n",
    "(주)씨제이이엔엠, A\n",
    "(주)아센디오, D\n",
    "(주)아이오케이컴퍼니, D\n",
    "(주)애니플러스, C\n",
    "(주)에이스메이커무비웍스, B\n",
    "(주)엣나인필름, B\n",
    "(주)영화사 그램, D\n",
    "(주)영화사 안다미로, D\n",
    "(주)영화사 진진, C\n",
    "(주)영화특별시에스엠씨, D\n",
    "(주)올스타엔터테인먼트, C\n",
    "(주)이놀미디어, D\n",
    "(주)제이앤씨미디어그룹, D\n",
    "(주)케이티알파, D\n",
    "(주)콘텐츠지오, D\n",
    "(주)키다리스튜디오, B\n",
    "(주)티캐스트, C\n",
    "(주)팝엔터테인먼트, C\n",
    "(주)플레이그램, D\n",
    "(주)하이스트레인저, D\n",
    "(주)홈초이스, D\n",
    "CGV ICECON, A\n",
    "M&M 인터내셔널, C\n",
    "TCO(주)더콘텐츠온, C\n",
    "그린나래미디어(주), C\n",
    "다큐스토리, D\n",
    "더핑크퐁컴퍼니(주), D\n",
    "롯데컬처웍스(주)롯데시네마, A\n",
    "롯데컬처웍스(주)롯데엔터테인먼트, A\n",
    "롯데컬처웍스(주)롯시플, A\n",
    "리바이브콘텐츠 주식회사, D\n",
    "메가박스중앙(주), A\n",
    "미디어나무(주), D\n",
    "소니픽쳐스엔터테인먼트코리아주식회사극장배급지점, A\n",
    "스튜디오 에이드, D\n",
    "스튜디오두마, D\n",
    "씨제이 씨지브이(CJ CGV)(주), A\n",
    "씨제이포디플렉스 주식회사, A\n",
    "에스엠지홀딩스 주식회사, D\n",
    "오드, C\n",
    "와이드 릴리즈(주), C\n",
    "워너브러더스 코리아(주), A\n",
    "워터홀컴퍼니(주), C\n",
    "월트디즈니컴퍼니코리아 유한책임회사, A\n",
    "유니버설픽쳐스인터내셔널 코리아(유), B\n",
    "유한회사 엠프로젝트, D\n",
    "주식회사 블루필름웍스, D\n",
    "주식회사 에이비오엔터테인먼트, D\n",
    "주식회사 에이투지엔터테인먼트, D\n",
    "주식회사 올랄라스토리, D\n",
    "주식회사 왓챠, C\n",
    "주식회사 필름영, C\n",
    "찬란, C\n",
    "트윈플러스파트너스(주), D\n",
    "판씨네마(주), B\n",
    "플러스엠 엔터테인먼트, A\n",
    "홀리가든, D\"\"\"\n",
    "\n",
    "# 빈 리스트 초기화\n",
    "distributors_list = []\n",
    "grades_list = []\n",
    "\n",
    "# 데이터를 줄 단위로 나누기\n",
    "lines = data.strip().split('\\n')\n",
    "for line in lines:\n",
    "    distributor, grade = line.strip().rsplit(',', 1)\n",
    "    distributors_list.append(distributor.strip())\n",
    "    grades_list.append(grade.strip())\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({\n",
    "    'Distributor': distributors_list,\n",
    "    '평가': grades_list\n",
    "})\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "output_csv_file_path = 'distributors.csv'\n",
    "df.to_csv(output_csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Distributor와 평가 컬럼이 포함된 CSV 파일이 {output_csv_file_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a854108-c0b8-486e-96e1-0b54c863bf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributor_Sc 컬럼이 포함된 CSV 파일이 preprosessing_ver3.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "movies_csv_path = '0530_dataset\\preprosessing_ver2.csv'\n",
    "distributors_csv_path = '0530_dataset\\distributors.csv'\n",
    "output_csv_path = 'preprosessing_ver3.csv'\n",
    "\n",
    "# 영화 데이터와 배급사 평가 데이터를 읽기\n",
    "movies_df = pd.read_csv(movies_csv_path)\n",
    "distributors_df = pd.read_csv(distributors_csv_path)\n",
    "\n",
    "# 배급사 평가 데이터를 딕셔너리로 변환\n",
    "distributor_grades = dict(zip(distributors_df['Distributor'], distributors_df['평가']))\n",
    "\n",
    "def evaluate_distributors(distributor_str, grades_dict):\n",
    "    # 배급사 문자열을 분리\n",
    "    distributors = [d.strip() for d in distributor_str.split(',')]\n",
    "    # 배급사 등급 리스트 생성\n",
    "    grades = [grades_dict.get(d, 'D') for d in distributors]\n",
    "    \n",
    "    # 평가 기준 적용\n",
    "    if 'A' in grades:\n",
    "        return 'A'\n",
    "    elif 'B' in grades:\n",
    "        return 'B'\n",
    "    elif 'C' in grades:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "# Distributor_Sc 컬럼 추가\n",
    "movies_df['Distributor_Sc'] = movies_df['Distributor'].apply(evaluate_distributors, grades_dict=distributor_grades)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "movies_df.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Distributor_Sc 컬럼이 포함된 CSV 파일이 {output_csv_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8e1cf5-cab8-484a-8e61-3926689b47a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감독 이름이 비어 있는 영화 제목:\n",
      "['슈퍼 마리오 브라더스', '던전 앤 드래곤: 도적들의 명예', '그란 투리스모', '말하고 싶은 비밀', '아기상어 극장판: 사이렌 스톤의 비밀', '극장판 도라에몽: 진구와 하늘의 유토피아', '아이유 콘서트 : 더 골든 아워', '바다 탐험대 옥토넛 어보브 앤 비욘드 : 육지 넘어 하늘까지!', '바다 탐험대 옥토넛 : 탐험선 대작전', '유미의 세포들 더 무비', '바다 탐험대 옥토넛 어보브 앤 비욘드: 버드, 옥토경보를 울려라!', '이빨요정 비올레타: 요정나라로 돌아갈래!', '바다 탐험대 옥토넛 육지수호 대작전 : 열대우림을 지켜라!', '정글번치: 월드투어', '애프터썬', '비투비 타임 : 비투게더 더 무비', '테일러 스위프트 디 에라스 투어', '돌핀보이', '너는 내 아들', '이승윤 콘서트 도킹 : 리프트오프', '루이스 웨인: 사랑을 그린 고양이 화가', '극장판 바다 탐험대 옥토넛 : 해저동굴 대탈출']\n",
      "배우가 비어 있는 영화 제목:\n",
      "['엘리멘탈', '더 퍼스트 슬램덩크', '건국전쟁', '신차원! 짱구는 못말려 더 무비 초능력 대결전 ~날아라 수제김밥~', '극장판 짱구는 못말려: 수수께끼! 꽃피는 천하떡잎학교', '명탐정코난: 흑철의 어영', '극장판 짱구는 못말려: 동물소환 닌자 배꼽수비대', '귀멸의 칼날: 인연의 기적, 그리고 합동 강화 훈련으로', '명탐정 코난: 할로윈의 신부', '원피스 필름 레드', '톡 투 미', '포켓몬스터: 성도지방 이야기, 최종장', '눈의 여왕5: 스노우 프린세스와 미러랜드의 비밀', '두다다쿵: 후후섬의 비밀', '그란 투리스모', '문재인입니다', '사나: 저주의 아이', '바다 탐험대 옥토넛 어보브 앤 비욘드: 버드, 옥토경보를 울려라!', '크레센도', '이빨요정 비올레타: 요정나라로 돌아갈래!', '런닝맨: 리벤져스', '마야 3: 숲속 왕국의 위기', '정글번치: 월드투어', '아인보: 아마존의 전설', '마브카 : 숲의 노래', '로봇 드림', '2022 영탁 단독 콘서트 \"탁쇼\"', '틴에이지 크라켄 루비', '엔드 오브 에반게리온', '비투비 타임 : 비투게더 더 무비', '테일러 스위프트 디 에라스 투어', '사랑은 낙엽을 타고', '너는 내 아들', '이승윤 콘서트 도킹 : 리프트오프', '극장판 엉덩이 탐정: 수플레 섬의 비밀', '나의 히어로 아카데미아 더 무비: 월드 히어로즈 미션']\n",
      "감독 이름과 배우가 둘 다 비어 있는 영화 제목:\n",
      "['그란 투리스모', '바다 탐험대 옥토넛 어보브 앤 비욘드: 버드, 옥토경보를 울려라!', '이빨요정 비올레타: 요정나라로 돌아갈래!', '정글번치: 월드투어', '비투비 타임 : 비투게더 더 무비', '테일러 스위프트 디 에라스 투어', '너는 내 아들', '이승윤 콘서트 도킹 : 리프트오프']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "movies_csv_path = '0530_dataset/preprosessing_ver3.csv'\n",
    "\n",
    "# 영화 데이터 읽기\n",
    "movies_df = pd.read_csv(movies_csv_path)\n",
    "\n",
    "# 감독 이름과 배우가 비어 있는 행 필터링\n",
    "empty_director_movies = movies_df[movies_df['Director'].isna() | (movies_df['Director'].str.strip() == '')]\n",
    "empty_actors_movies = movies_df[movies_df['Actors'].isna() | (movies_df['Actors'].str.strip() == '')]\n",
    "\n",
    "# 둘 다 비어 있는 행 필터링\n",
    "empty_both_movies = movies_df[(movies_df['Director'].isna() | (movies_df['Director'].str.strip() == '')) &\n",
    "                              (movies_df['Actors'].isna() | (movies_df['Actors'].str.strip() == ''))]\n",
    "\n",
    "# 감독 이름이 비어 있는 영화 제목\n",
    "print(\"감독 이름이 비어 있는 영화 제목:\")\n",
    "print(empty_director_movies['Movie_Title'].tolist())\n",
    "\n",
    "# 배우가 비어 있는 영화 제목\n",
    "print(\"배우가 비어 있는 영화 제목:\")\n",
    "print(empty_actors_movies['Movie_Title'].tolist())\n",
    "\n",
    "# 감독 이름과 배우가 둘 다 비어 있는 영화 제목\n",
    "print(\"감독 이름과 배우가 둘 다 비어 있는 영화 제목:\")\n",
    "print(empty_both_movies['Movie_Title'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e7494a-e6e2-4818-9bd5-cd9885a0dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Movie_Title          Director  \\\n",
      "7                                    엘리멘탈              피터 손   \n",
      "11                             더 퍼스트 슬램덩크         이노우에 다케히코   \n",
      "24                            슈퍼 마리오 브라더스               NaN   \n",
      "47                                   건국전쟁               김덕영   \n",
      "53   신차원! 짱구는 못말려 더 무비 초능력 대결전 ~날아라 수제김밥~            오네 히토시   \n",
      "59          극장판 짱구는 못말려: 수수께끼! 꽃피는 천하떡잎학교          타카하시 와타루   \n",
      "61                          명탐정코난: 흑철의 어영          타치카와 유즈루   \n",
      "66             극장판 짱구는 못말려: 동물소환 닌자 배꼽수비대         하시모토 마사카즈   \n",
      "83         귀멸의 칼날: 인연의 기적, 그리고 합동 강화 훈련으로          소토자키 하루오   \n",
      "84                        명탐정 코난: 할로윈의 신부          미츠나카 스스무   \n",
      "110                     던전 앤 드래곤: 도적들의 명예               NaN   \n",
      "127                             원피스 필름 레드           타니구치 고로   \n",
      "131                                 톡 투 미    대니 필리푸,마이클 필리푸   \n",
      "139                  포켓몬스터: 성도지방 이야기, 최종장          유야마 쿠니히코   \n",
      "141            눈의 여왕5: 스노우 프린세스와 미러랜드의 비밀         알렉세이 트시칠린   \n",
      "147                         두다다쿵: 후후섬의 비밀           최병선,김지윤   \n",
      "149                               그란 투리스모               NaN   \n",
      "152                             말하고 싶은 비밀               NaN   \n",
      "153                                문재인입니다               이창재   \n",
      "161                  아기상어 극장판: 사이렌 스톤의 비밀               NaN   \n",
      "167                극장판 도라에몽: 진구와 하늘의 유토피아               NaN   \n",
      "171                     아이유 콘서트 : 더 골든 아워               NaN   \n",
      "172    바다 탐험대 옥토넛 어보브 앤 비욘드 : 육지 넘어 하늘까지!               NaN   \n",
      "173                            사나: 저주의 아이           시미즈 다카시   \n",
      "177                  바다 탐험대 옥토넛 : 탐험선 대작전               NaN   \n",
      "179                          유미의 세포들 더 무비               NaN   \n",
      "183  바다 탐험대 옥토넛 어보브 앤 비욘드: 버드, 옥토경보를 울려라!               NaN   \n",
      "184                                  크레센도             헤더 윌크   \n",
      "194                이빨요정 비올레타: 요정나라로 돌아갈래!               NaN   \n",
      "196      바다 탐험대 옥토넛 육지수호 대작전 : 열대우림을 지켜라!               NaN   \n",
      "203                             런닝맨: 리벤져스               엄영식   \n",
      "205                       마야 3: 숲속 왕국의 위기           노엘 클리어리   \n",
      "208                            정글번치: 월드투어               NaN   \n",
      "209                          아인보: 아마존의 전설   리처드 클라우스,호세 젤라다   \n",
      "210                           마브카 : 숲의 노래             올레말라므   \n",
      "214                                  애프터썬               NaN   \n",
      "217                                 로봇 드림          파블로 베르헤르   \n",
      "222                   2022 영탁 단독 콘서트 \"탁쇼\"               송승연   \n",
      "227                           틴에이지 크라켄 루비           커크 드 미코   \n",
      "237                           엔드 오브 에반게리온  안노 히데아키,츠루마키 카즈야   \n",
      "239                    비투비 타임 : 비투게더 더 무비               NaN   \n",
      "241                     테일러 스위프트 디 에라스 투어               NaN   \n",
      "244                            사랑은 낙엽을 타고         아키 카우리스마키   \n",
      "251                                  돌핀보이               NaN   \n",
      "259                               너는 내 아들               NaN   \n",
      "261                    이승윤 콘서트 도킹 : 리프트오프               NaN   \n",
      "282                 극장판 엉덩이 탐정: 수플레 섬의 비밀           자코 아키후미   \n",
      "293         나의 히어로 아카데미아 더 무비: 월드 히어로즈 미션           나가사키 켄지   \n",
      "294                 루이스 웨인: 사랑을 그린 고양이 화가               NaN   \n",
      "298             극장판 바다 탐험대 옥토넛 : 해저동굴 대탈출               NaN   \n",
      "\n",
      "                                                Actors  \n",
      "7                                                  NaN  \n",
      "11                                                 NaN  \n",
      "24                         크리스 프랫,안야 테일러 조이,잭 블랙,찰리 데이  \n",
      "47                                                 NaN  \n",
      "53                                                 NaN  \n",
      "59                                                 NaN  \n",
      "61                                                 NaN  \n",
      "66                                                 NaN  \n",
      "83                                                 NaN  \n",
      "84                                                 NaN  \n",
      "110    크리스 파인,미셸 로드리게즈,레게-장 페이지,저스티스 스미스,소피아 릴리스,휴 그랜트  \n",
      "127                                                NaN  \n",
      "131                                                NaN  \n",
      "139                                                NaN  \n",
      "141                                                NaN  \n",
      "147                                                NaN  \n",
      "149                                                NaN  \n",
      "152                                           사쿠라다 히요리  \n",
      "153                                                NaN  \n",
      "161  장예나,전태열,이희승(엔하이픈),박종성(엔하이픈),심재윤(엔하이픈),박성훈(엔하이픈...  \n",
      "167                                윤아영,김정아,이현주,조현정,최낙윤  \n",
      "171                                                이지은  \n",
      "172                 하성용,정재헌,엄상현,윤승희,김율,유동균,김정은,한경화,박성영  \n",
      "173                                                NaN  \n",
      "177                     하성용,정재헌,엄상현,윤승희,김율,유동균,김정은,한경화  \n",
      "179                            윤아영,신범식,송하림,안소이,사문영,안영미  \n",
      "183                                                NaN  \n",
      "184                                                NaN  \n",
      "194                                                NaN  \n",
      "196             하성용,정재헌,엄상현,윤승희,김율,유동균,김정은,한경화,박성영,이재현  \n",
      "203                                                NaN  \n",
      "205                                                NaN  \n",
      "208                                                NaN  \n",
      "209                                                NaN  \n",
      "210                                                NaN  \n",
      "214                                              폴 메스칼  \n",
      "217                                                NaN  \n",
      "222                                                NaN  \n",
      "227                                                NaN  \n",
      "237                                                NaN  \n",
      "239                                                NaN  \n",
      "241                                                NaN  \n",
      "244                                                NaN  \n",
      "251                                                박시윤  \n",
      "259                                                NaN  \n",
      "261                                                NaN  \n",
      "282                                                NaN  \n",
      "293                                                NaN  \n",
      "294  베네딕트 컴버배치,클레어 포이,올리비아 콜맨,토비 존스,안드레아 라이즈보로,스테이시...  \n",
      "298                  하성용,정재헌,엄상현,윤승희,김율,유동균,김정은,한경화,장미  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "movies_csv_path = '0530_dataset/preprosessing_ver3.csv'\n",
    "\n",
    "# 영화 데이터 읽기\n",
    "movies_df = pd.read_csv(movies_csv_path)\n",
    "\n",
    "# 감독 이름 또는 배우가 비어 있는 행 필터링\n",
    "empty_director_or_actors_movies = movies_df[movies_df['Director'].isna() | (movies_df['Director'].str.strip() == '') |\n",
    "                                            movies_df['Actors'].isna() | (movies_df['Actors'].str.strip() == '')]\n",
    "\n",
    "# 감독 이름 또는 배우가 비어 있는 행 삭제\n",
    "cleaned_movies_df = movies_df.drop(empty_director_or_actors_movies.index)\n",
    "\n",
    "# 삭제된 행 정보\n",
    "deleted_movies = empty_director_or_actors_movies[['Movie_Title', 'Director', 'Actors']]\n",
    "\n",
    "print(deleted_movies)\n",
    "# 저장된 데이터를 새로운 CSV 파일로 저장 (원본 데이터를 덮어쓰지 않기 위해 경로 변경)\n",
    "cleaned_movies_csv_path = 'cleaned_preprosessing_ver3.csv'\n",
    "cleaned_movies_df.to_csv(cleaned_movies_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7622b8e8-3834-484a-9634-98fa8065c8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Movie_Title     w1_av_sc     w2_av_sc     w3_av_sc\n",
      "0         서울의 봄  1062.717386  1189.735052  1074.807535\n",
      "1            파묘  1560.289309  1501.112580   898.330183\n",
      "2         범죄도시4  1735.738878  1370.078330   606.151817\n",
      "3     아바타: 물의 길  1154.896109  1265.188198   974.919402\n",
      "4         범죄도시3  2527.987292   951.132874   741.933813\n",
      "..          ...          ...          ...          ...\n",
      "247    나이트메어 앨리    68.311025    51.121013    59.029851\n",
      "248     어나더 라운드    88.648438   172.478261   133.559229\n",
      "249         시라노   106.430614    26.863158    43.633333\n",
      "250     리코리쉬 피자    65.677918    43.432308    48.137441\n",
      "251      우연과 상상   205.234463   106.270950    80.111111\n",
      "\n",
      "[252 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'updated_file.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Update w2_au and w3_au for all rows\n",
    "df['w1_av_sc'] = df['w1_au'] / df['w1_av_sc']\n",
    "df['w2_av_sc'] = df['w2_au'] / df['w2_av_sc']\n",
    "df['w3_av_sc'] = df['w3_au'] / df['w3_av_sc']\n",
    "\n",
    "# 업데이트된 데이터프레임을 확인합니다\n",
    "print(df[['Movie_Title', 'w1_av_sc', 'w2_av_sc', 'w3_av_sc']])\n",
    "\n",
    "# 변경된 내용을 새로운 CSV 파일로 저장합니다\n",
    "df.to_csv('updated_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "991cba20-5dd6-4c8d-9633-ac124d0f1433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       w1_au    w2_au     w1_av_sc     w2_av_sc\n",
      "0    2364698  2703248  1062.717386  1189.735052\n",
      "1    3312940  3293441  1560.289309  1501.112580\n",
      "2    5005375  3713108  1735.738878  1370.078330\n",
      "3    3201537  2814863  1154.896109  1265.188198\n",
      "4    6053085  1993031  2527.987292   951.132874\n",
      "..       ...      ...          ...          ...\n",
      "247    27705     7785    68.311025    51.121013\n",
      "248    14589     7934    88.648438   172.478261\n",
      "249    18078     2552   106.430614    26.863158\n",
      "250    13342     4033    65.677918    43.432308\n",
      "251    10379     5435   205.234463   106.270950\n",
      "\n",
      "[252 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'updated_file.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 필요한 컬럼만 추출\n",
    "selected_columns = df[['w1_au', 'w2_au', 'w1_av_sc', 'w2_av_sc']]\n",
    "\n",
    "# 추출한 데이터프레임을 확인합니다\n",
    "print(selected_columns)\n",
    "\n",
    "# 추출한 내용을 새로운 CSV 파일로 저장합니다\n",
    "selected_columns.to_csv('selected_columns.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae2b520-ba93-4954-aa91-37d949d57aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          NaN         1         2                  3                   4  \\\n",
      "0        서울의 봄  55.50419  73.67073           79.25816   71.19690682872215   \n",
      "1           파묘  67.49954  82.78116  75.60018635864003   84.74670131624185   \n",
      "2        범죄도시4     100.0  84.14176           70.42814    31.6227952530688   \n",
      "3    아바타: 물의 길  84.31055  82.30668           81.87475   75.60018635864003   \n",
      "4        범죄도시3  95.40589   93.4583           83.45108   75.60018635864003   \n",
      "..         ...       ...       ...                ...                 ...   \n",
      "247   나이트메어 앨리  82.97027  75.13949           76.48352   75.60018635864003   \n",
      "248    어나더 라운드  72.34199  74.63083           89.75191   75.60018635864003   \n",
      "249        시라노     100.0   94.2359           92.18332   69.12874743020433   \n",
      "250    리코리쉬 피자  93.22194   84.3693           85.79459   75.60018635864003   \n",
      "251     우연과 상상  66.60961     100.0           92.80358  37.830231116100606   \n",
      "\n",
      "0                    5         6         7  \n",
      "0    91.71449075599527  88.93493  72.35861  \n",
      "1             78.13019  54.66054  51.43671  \n",
      "2     46.6069551919917  50.76426  42.00864  \n",
      "3    68.31440624890186  57.97047  53.22427  \n",
      "4    87.46481854289252  75.90528  73.95812  \n",
      "..                 ...       ...       ...  \n",
      "247  81.09143155197474  70.44479  55.09979  \n",
      "248  63.45658098640107  64.11695  56.34967  \n",
      "249  67.91814340626563  63.82679  56.36159  \n",
      "250  80.47638683253291  68.49315  62.11101  \n",
      "251  52.97137155301878  66.71556  56.38141  \n",
      "\n",
      "[252 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = '0530_dataset\\combined_trend_data_adjusted.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# 'period' 행 제거\n",
    "df = df[df[0] != 'period']\n",
    "\n",
    "# 컬럼명을 첫 번째 행으로 설정\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "\n",
    "# 인덱스를 새로 설정\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 업데이트된 데이터프레임을 확인합니다\n",
    "print(df)\n",
    "\n",
    "# 변경된 내용을 새로운 CSV 파일로 저장합니다\n",
    "df.to_csv('updated_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406a377f-ad2f-4f5c-a3c0-7b12c63a420a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '0530_dataset\\trend_data_ver1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# CSV 파일 읽기\u001b[39;00m\n\u001b[0;32m      5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0530_dataset\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mrend_data_ver1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 파일 경로를 지정하세요\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 정규화 함수\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(series):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: '0530_dataset\\trend_data_ver1.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = '0530_dataset\\trend_data_ver1.csv'  # 파일 경로를 지정하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 정규화 함수\n",
    "def normalize(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "# 단순선형회귀를 계산하는 함수\n",
    "def linear_regression_slope(x, y):\n",
    "    n = len(x)\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    numerator = np.sum((x - x_mean) * (y - y_mean))\n",
    "    denominator = np.sum((x - x_mean) ** 2)\n",
    "    slope = numerator / denominator\n",
    "    return slope\n",
    "\n",
    "# 각 행에 대해 정규화 및 회귀 기울기 계산\n",
    "slopes = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # 1~7번 컬럼 선택 및 정규화\n",
    "    data = row[1:8].astype(float)\n",
    "    normalized_data = normalize(data)\n",
    "    \n",
    "    # 단순선형회귀 수행\n",
    "    X = np.arange(len(normalized_data))\n",
    "    y = normalized_data.values\n",
    "    slope = linear_regression_slope(X, y)\n",
    "    \n",
    "    # 기울기를 리스트에 추가\n",
    "    slopes.append(slope)\n",
    "\n",
    "# 새로운 컬럼으로 기울기 추가\n",
    "df['slope'] = slopes\n",
    "\n",
    "# 결과 출력\n",
    "print(df)\n",
    "\n",
    "# 변경된 내용을 새로운 CSV 파일로 저장합니다\n",
    "df.to_csv('updated_file_with_slopes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fb3640-fd14-4b4e-9f6b-79fe7bf544c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범죄도시4\n",
      "범죄도시3\n",
      "노량: 죽음의 바다\n",
      "육사오(6/45)\n",
      "오늘 밤, 세계에서 이 사랑이 사라진다 해도\n",
      "1947 보스톤\n",
      "남은 인생 10년\n",
      "늑대사냥\n",
      "상견니\n",
      "탄생\n",
      "아임 히어로 더 파이널\n",
      "마루이 비디오\n",
      "길위에 김대중\n",
      "화사한 그녀\n",
      "방탄소년단: 옛 투 컴 인 시네마\n",
      "쏘우 X\n",
      "익스펜더블 4\n",
      "신체모음.zip\n",
      "수라\n",
      "슬픔의 삼각형\n",
      "바람 따라 만나리 : 김호중의 계절\n",
      "류이치 사카모토: 오퍼스\n",
      "인생은 뷰티풀: 비타돌체\n",
      "엔니오: 더 마에스트로\n",
      "사랑할 땐 누구나 최악이 된다\n",
      "악은 존재하지 않는다\n",
      "더 와일드: 야수들의 전쟁\n",
      "애프터 양\n",
      "너와 나\n",
      "썸머 필름을 타고!\n",
      "네가 떨어뜨린 푸른 하늘\n",
      "괴담만찬\n",
      "스트리머\n",
      "범죄도시2\n",
      "뜨거운 피\n",
      "스펜서\n",
      "우연과 상상\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = '0530_dataset\\preprosessing_ver7_r4.csv'  # 여기에 실제 CSV 파일 경로를 입력하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Distributor 열에서 두 개 이상의 값이 포함된 Movie_Title 출력\n",
    "for index, row in df.iterrows():\n",
    "    distributors = row['Distributor'].split(',')  # 쉼표를 기준으로 분리\n",
    "    if len(distributors) > 1:\n",
    "        print(row['Movie_Title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd56205-cf35-46bd-9077-c73524f6a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# 예시 데이터 생성\n",
    "data = \"\"\"Distributor,Grade\n",
    "(주)넥스트엔터테인먼트월드(NEW),A\n",
    "(주)누리픽쳐스,D\n",
    "(주)대교 미디어콘텐츠사업본부,D\n",
    "(주)디스테이션,C\n",
    "(주)라이크콘텐츠,D\n",
    "(주)레드아이스 엔터테인먼트,D\n",
    "(주)마인드마크,D\n",
    "(주)명필름,D\n",
    "(주)무비다이브,D\n",
    "(주)미디어캐슬,C\n",
    "(주)바른손이앤에이,D\n",
    "(주)바이포엠스튜디오,D\n",
    "(주)박수엔터테인먼트,C\n",
    "(주)버킷스튜디오,D\n",
    "(주)블루라벨픽쳐스,D\n",
    "(주)쇼박스,A\n",
    "(주)스마일이엔티,B\n",
    "(주)스튜디오 산타클로스엔터테인먼트,D\n",
    "(주)스튜디오디에이치엘,D\n",
    "(주)시네마6411,D\n",
    "(주)시네마달,D\n",
    "(주)싸이더스,B\n",
    "(주)씨네필운,D\n",
    "(주)씨제이이엔엠,A\n",
    "(주)아센디오,D\n",
    "(주)아이오케이컴퍼니,D\n",
    "(주)애니플러스,C\n",
    "(주)에이스메이커무비웍스,B\n",
    "(주)엣나인필름,B\n",
    "(주)영화사 그램,D\n",
    "(주)영화사 안다미로,D\n",
    "(주)영화사 진진,C\n",
    "(주)영화특별시에스엠씨,D\n",
    "(주)올스타엔터테인먼트,C\n",
    "(주)이놀미디어,D\n",
    "(주)제이앤씨미디어그룹,D\n",
    "(주)케이티알파,D\n",
    "(주)콘텐츠지오,D\n",
    "(주)키다리스튜디오,B\n",
    "(주)티캐스트,C\n",
    "(주)팝엔터테인먼트,C\n",
    "(주)플레이그램,D\n",
    "(주)하이스트레인저,D\n",
    "(주)홈초이스,D\n",
    "CGV ICECON,A\n",
    "M&M 인터내셔널,C\n",
    "TCO(주)더콘텐츠온,C\n",
    "그린나래미디어(주),C\n",
    "다큐스토리,D\n",
    "더핑크퐁컴퍼니(주),D\n",
    "롯데컬처웍스(주)롯데시네마,A\n",
    "롯데컬처웍스(주)롯데엔터테인먼트,A\n",
    "롯데컬처웍스(주)롯시플,A\n",
    "리바이브콘텐츠 주식회사,D\n",
    "메가박스중앙(주),A\n",
    "미디어나무(주),D\n",
    "소니픽쳐스엔터테인먼트코리아주식회사극장배급지점,A\n",
    "스튜디오 에이드,D\n",
    "스튜디오두마,D\n",
    "씨제이 씨지브이(CJ CGV)(주),A\n",
    "씨제이포디플렉스 주식회사,A\n",
    "에스엠지홀딩스 주식회사,D\n",
    "오드,C\n",
    "와이드 릴리즈(주),C\n",
    "워너브러더스 코리아(주),A\n",
    "워터홀컴퍼니(주),C\n",
    "월트디즈니컴퍼니코리아 유한책임회사,A\n",
    "유니버설픽쳐스인터내셔널 코리아(유),B\n",
    "유한회사 엠프로젝트,D\n",
    "주식회사 블루필름웍스,D\n",
    "주식회사 에이비오엔터테인먼트,D\n",
    "주식회사 에이투지엔터테인먼트,D\n",
    "주식회사 올랄라스토리,D\n",
    "주식회사 왓챠,C\n",
    "주식회사 필름영,C\n",
    "찬란,C\n",
    "트윈플러스파트너스(주),D\n",
    "판씨네마(주),B\n",
    "플러스엠 엔터테인먼트,A\n",
    "홀리가든,D\"\"\"\n",
    "\n",
    "# StringIO를 사용하여 데이터프레임으로 읽기\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# Distributor와 Grade를 딕셔너리로 변환\n",
    "distributor_grade_dict = dict(zip(df['Distributor'], df['Grade']))\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = '0530_dataset/preprosessing_ver7_r4.csv'  # 여기에 실제 CSV 파일 경로를 입력하세요\n",
    "\n",
    "# CSV 파일 읽기\n",
    "movies_df = pd.read_csv(file_path)\n",
    "\n",
    "# one_Distributor 열을 None으로 초기화\n",
    "movies_df['one_Distributor'] = None\n",
    "\n",
    "# 등급 순서 정의\n",
    "grade_order = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n",
    "\n",
    "# 데이터를 처리하여 one_Distributor 열 채우기\n",
    "for index, row in movies_df.iterrows():\n",
    "    distributors = row['Distributor'].split(',')\n",
    "    if len(distributors) == 1:\n",
    "        movies_df.at[index, 'one_Distributor'] = distributors[0].strip()\n",
    "    elif len(distributors) > 1:\n",
    "        highest_grade_distributor = None\n",
    "        highest_grade = float('inf')\n",
    "        for distributor in distributors:\n",
    "            distributor = distributor.strip()\n",
    "            grade = distributor_grade_dict.get(distributor, 'D')\n",
    "            if grade_order[grade] < highest_grade:\n",
    "                highest_grade = grade_order[grade]\n",
    "                highest_grade_distributor = distributor\n",
    "\n",
    "        movies_df.at[index, 'one_Distributor'] = highest_grade_distributor\n",
    "\n",
    "# 등급이 같은 데이터가 있는 경우 모든 데이터를 넣은 행의 Movie_Title을 출력\n",
    "titles_with_multiple_high_grades = movies_df[movies_df['one_Distributor'].str.contains(',')]\n",
    "for title in titles_with_multiple_high_grades['Movie_Title']:\n",
    "    print(title)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "movies_df.to_csv('0530_dataset/preprosessing_ver7_r5.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbc1788-3b86-4f7c-8bf4-2f349e7c4050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Pc_code' 열이 제거된 CSV 파일이 저장되었습니다: 0530_dataset/preprosessing_ver7_r6.csv.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = '0530_dataset/preprosessing_ver7_r5.csv'  # 여기에 실제 CSV 파일 경로를 입력하세요\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Pc_code 열 제거\n",
    "if 'Pc_code' in df.columns:\n",
    "    df = df.drop(columns=['Pc_code'])\n",
    "\n",
    "# 수정된 데이터프레임을 새로운 CSV 파일로 저장\n",
    "output_file_path = '0530_dataset/preprosessing_ver7_r6.csv.csv'  # 여기에 저장할 파일 경로를 입력하세요\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"'Pc_code' 열이 제거된 CSV 파일이 저장되었습니다: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23066c75-6106-44c6-8c8d-ba8280fa0cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['범죄도시2', '마녀(魔女) Part2. The Other One', '닥터 스트레인지: 대혼돈의 멀티버스', '그대가 조국', '애프터 양', '극장판 주술회전 0', '큐어', '카시오페아', '배드 가이즈', '안녕하세요', '안녕하세요', '안녕하세요', '니얼굴', '아치의 노래, 정태춘', '듣보인간의 생존신고', '몬스터 싱어: 매직 인 파리', '니 부모 얼굴이 보고 싶다', '특수요원 빼꼼', '성덕', '모어', '풀타임', '오마주', '애프터 미투', '수프와 이데올로기', '뜨거운 피: 디 오리지널', '가가린', '베르네 부인의 장미정원', '피는 물보다 진하다', '메모리아', '같은 속옷을 입는 두 여자', '광대: 소리꾼', '창밖은 겨울', '뜨거운 피', '로스트 시티', '썬다운', '우연과 상상', '수퍼 소닉2', '거래완료', '이공삼칠', '그 겨울, 나는', '미친 능력', '낮과 달', '앵커', '나를 만나는 길', '극장판 엉덩이 탐정: 수플레 섬의 비밀', '절해고도', '낮에는 덥고 밤에는 춥고', '어부바', '더 노비스', '흐르다', '흐르다', '말임씨를 부탁해', '궁지에 몰린 쥐는 치즈 꿈을 꾼다', '스텔라', '스텔라', '더 컨트랙터', '민스미트 작전', '윤시내가 사라졌다', '말아', '앰뷸런스', '봄날', '신비한 동물들과 덤블도어의 비밀', '매스', '더 배트맨', '토르: 마법 검의 전설', '불도저에 탄 소녀', '공기살인', '플레이그라운드', '쿠폰의 여왕', '파리, 13구', '씽2게더', '처음 꽃향기를 만난 순간', '재춘언니', '붉은 사막', '극장판 금빛 모자이크 땡큐!!', '컨버세이션', '셧 인', '모비우스', '올리 마키의 가장 행복한 날', '창극 변강쇠 점 찍고 옹녀', '세월: 라이프 고즈 온', '벗어날 탈 脫', '극장판 안녕 자두야: 제주도의 비밀', '배니싱: 미제사건', '모퉁이', '미싱타는 여자들', '퍼스트 러브', '이상한 나라의 수학자', '군다', '작은새와 돼지씨', '루이스 웨인: 사랑을 그린 고양이 화가', '신데렐라', '신데렐라', '소설가의 영화', '히든', '피아노 프리즘', '걸즈 앤 판처 최종장 제3화', '봉명주공', '레드 로켓', '일 부코', '인연을 긋다', '몬스터 아카데미', '웨스트 사이드 스토리', '오늘부터 우리는!!', '시라노', '어나더 라운드', '소설의 신', '완벽한 축사를 준비하는 방법', '보드랍게', '우리가 사랑이라고 믿는 것', '리골레토', '리골레토', '킹메이커', '복지식당', '해탄적일천', '허셀프', '1975 킬링필드, 푸난', '태어나길 잘했어', '그래니트: 트루 솔저', '서울괴담', '엄마와 나', '킹 리차드', '스펜서', '명색이 아프레걸', '어거스트 버진', '파리의 피아니스트: 후지코 헤밍의 시간들', '프리! 더 파이널 스트로크 전편', '로망스 돌', '하늘의 푸르름을 아는 사람이여', '데드캠핑 더라이브', '액션동자', '패러렐 마더스', '비욘드라이브 더 무비 : 엔시티 레조넌스', '내가 처음으로 사랑한 소녀', '피그', '리코리쉬 피자', '벨파스트', '역할들', '크로스 더 라인', '쥬라기 리턴즈', '허황옥 3일, 잃어버린 2천 년의 기억', '스프링 블라썸', '메이드인세운상가', '고양이들의 아파트', '사랑 후의 두 여자', '평평남녀', '행복을 전하는 편지', '나의 히어로 아카데미아 더 무비: 월드 히어로즈 미션', '우주에서 가장 밝은 지붕', '위대한 계약: 파주, 책, 도시', '레벤느망', '늦봄2020', '드라이', '쏴!쏴!쏴!쏴!탕', '해피 데스나이트', \"뱅드림! 팝핀' 드림!\", '하로동선', '프랑스', '나의 집은 어디인가', '전장의 피아니스트', '하우스 오브 구찌', '개인레슨', '쓰리: 아직 끝나지 않았다', '전투왕', '싫은 건 아니지만', '인어가 잠든 집', '매미소리', '존경하고 사랑하는 국민여러분', '축복의 집', '헝거', '욕망: 신세계', '잭 인 더 박스', '카사네 : 빼앗는 얼굴', '그리스도 디 오리진', '소피의 세계', '이터널 로드', '밤낮없는 장모님', '욕정 채운 수업', '조금은 서툰 20대 소라 무삭제', '팔마', '미인', '밀라노 두오모 콘서트', '온 세상이 하얗다']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 읽기\n",
    "file1_df = pd.read_excel('05_28.xlsx')\n",
    "file2_df = pd.read_excel('01_01.xlsx')\n",
    "\n",
    "# 조건 설정\n",
    "filtered_file2_df = file2_df[file2_df['Release_Date'] >= '2022-01-01']\n",
    "\n",
    "# 합집합\n",
    "merged_df = pd.merge(file1_df, filtered_file2_df, on='Movie_Title', how='inner')\n",
    "\n",
    "# Movie_Title 출력\n",
    "movie_titles = merged_df['Movie_Title'].tolist()\n",
    "print(movie_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab7490c-55a3-409c-b5d5-fc1ff53cf86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울의 봄\n",
      "파묘\n",
      "범죄도시4\n",
      "아바타: 물의 길\n",
      "범죄도시3\n",
      "탑건: 매버릭\n",
      "한산: 용의 출현\n",
      "공조2: 인터내셔날\n",
      "밀수\n",
      "노량: 죽음의 바다\n",
      "헌트\n",
      "가디언즈 오브 갤럭시: Volume 3\n",
      "미션 임파서블: 데드 레코닝 PART ONE\n",
      "콘크리트 유토피아\n",
      "웡카\n",
      "올빼미\n",
      "영웅\n",
      "오펜하이머\n",
      "쥬라기 월드: 도미니언\n",
      "마녀(魔女) Part2. The Other One\n",
      "토르: 러브 앤 썬더\n",
      "30일\n",
      "블랙 팬서: 와칸다 포에버\n",
      "비상선언\n",
      "듄: 파트2\n",
      "육사오(6/45)\n",
      "존 윅 4\n",
      "천박사 퇴마 연구소: 설경의 비밀\n",
      "헤어질 결심\n",
      "분노의 질주: 라이드 오어 다이\n",
      "교섭\n",
      "시민덕희\n",
      "앤트맨과 와스프: 퀀텀매니아\n",
      "외계+인 1부\n",
      "잠\n",
      "외계+인 2부\n",
      "달짝지근해: 7510\n",
      "브로커\n",
      "오늘 밤, 세계에서 이 사랑이 사라진다 해도\n",
      "인생은 아름다워\n",
      "드림\n",
      "비공식작전\n",
      "1947 보스톤\n",
      "댓글부대\n",
      "데시벨\n",
      "정직한 후보2\n",
      "아쿠아맨과 로스트 킹덤\n",
      "인디아나 존스: 운명의 다이얼\n",
      "블랙 아담\n",
      "트랜스포머: 비스트의 서막\n",
      "대외비\n",
      "자백\n",
      "프레디의 피자가게\n",
      "리바운드\n",
      "더 마블스\n",
      "귀공자\n",
      "유령\n",
      "인어공주\n",
      "플래시\n",
      "압꾸정\n",
      "바비\n",
      "남은 인생 10년\n",
      "괴물\n",
      "3일의 휴가\n",
      "더 문\n",
      "고질라 X 콩: 뉴 엠파이어\n",
      "동감\n",
      "소년들\n",
      "늑대사냥\n",
      "타겟\n",
      "스위치\n",
      "놉\n",
      "서치 2\n",
      "리멤버\n",
      "인시디어스: 빨간 문\n",
      "싱글 인 서울\n",
      "카운트\n",
      "에브리씽 에브리웨어 올 앳 원스\n",
      "상견니\n",
      "도그데이즈\n",
      "더 넌 2\n",
      "탄생\n",
      "소풍\n",
      "웅남이\n",
      "거미집\n",
      "용감한 시민\n",
      "화란\n",
      "크리에이터\n",
      "옥수역귀신\n",
      "아임 히어로 더 파이널\n",
      "데드맨\n",
      "소울메이트\n",
      "메간\n",
      "나폴레옹\n",
      "젠틀맨\n",
      "스턴트맨\n",
      "바빌론\n",
      "멍뭉이\n",
      "킬링 로맨스\n",
      "헝거게임: 노래하는 새와 뱀의 발라드\n",
      "오멘: 저주의 시작\n",
      "오펀: 천사의 탄생\n",
      "플라워 킬링 문\n",
      "마루이 비디오\n",
      "가여운 것들\n",
      "아가일\n",
      "보호자\n",
      "길위에 김대중\n",
      "패스트 라이브즈\n",
      "다음 소희\n",
      "에브리씽 에브리웨어 올 앳 원스+\n",
      "에어\n",
      "블랙폰\n",
      "스마일\n",
      "추락의 해부\n",
      "뉴 노멀\n",
      "비키퍼\n",
      "엘비스\n",
      "화사한 그녀\n",
      "방탄소년단: 옛 투 컴 인 시네마\n",
      "파벨만스\n",
      "엑소시스트: 믿는 자\n",
      "챌린저스\n",
      "샤잠! 신들의 분노\n",
      "보 이즈 어프레이드\n",
      "쏘우 X\n",
      "익스펜더블 4\n",
      "본즈 앤 올\n",
      "신체모음.zip\n",
      "시맨틱 에러: 더 무비\n",
      "수라\n",
      "티켓 투 파라다이스\n",
      "슬픔의 삼각형\n",
      "더 웨일\n",
      "애스터로이드 시티\n",
      "바람 따라 만나리 : 김호중의 계절\n",
      "류이치 사카모토: 오퍼스\n",
      "사운드 오브 프리덤\n",
      "인생은 뷰티풀: 비타돌체\n",
      "엔니오: 더 마에스트로\n",
      "고스트버스터즈: 오싹한 뉴욕\n",
      "사랑할 땐 누구나 최악이 된다\n",
      "악은 존재하지 않는다\n",
      "랜드 오브 배드\n",
      "더 와일드: 야수들의 전쟁\n",
      "애프터 양\n",
      "지오디 마스터피스 더 무비\n",
      "너와 나\n",
      "오토라는 남자\n",
      "씬\n",
      "TAR 타르\n",
      "플레인\n",
      "롱디\n",
      "골드핑거\n",
      "슈가│어거스트 디 투어 ‘디-데이’ 더 무비\n",
      "메이 디셈버\n",
      "썸머 필름을 타고!\n",
      "네가 떨어뜨린 푸른 하늘\n",
      "바튼 아카데미\n",
      "어른 김장하\n",
      "양자경의 더 모든 날 모든 순간\n",
      "괴담만찬\n",
      "이니셰린의 밴시\n",
      "리빙: 어떤 인생\n",
      "마이 샤이니 월드\n",
      "나의 올드 오크\n",
      "라이스보이 슬립스\n",
      "3000년의 기다림\n",
      "플로라 앤 썬\n",
      "큐어\n",
      "고속도로 가족\n",
      "천룡팔부: 교봉전\n",
      "스트리머\n",
      "스트리머\n",
      "닥터 스트레인지: 대혼돈의 멀티버스\n",
      "범죄도시2\n",
      "해적: 도깨비 깃발\n",
      "신비한 동물들과 덤블도어의 비밀\n",
      "더 배트맨\n",
      "킹메이커\n",
      "언차티드\n",
      "경관의 피\n",
      "이상한 나라의 수학자\n",
      "모비우스\n",
      "특송\n",
      "니 부모 얼굴이 보고 싶다\n",
      "뜨거운 피\n",
      "나일 강의 죽음\n",
      "문폴\n",
      "앵커\n",
      "하우스 오브 구찌\n",
      "웨스트 사이드 스토리\n",
      "앰뷸런스\n",
      "서울괴담\n",
      "안테벨룸\n",
      "스텔라\n",
      "스펜서\n",
      "인민을 위해 복무하라\n",
      "그대가 조국\n",
      "나의 촛불\n",
      "나이트메어 앨리\n",
      "어나더 라운드\n",
      "시라노\n",
      "리코리쉬 피자\n",
      "우연과 상상\n",
      "앰뷸런스\n",
      "젠틀맨\n",
      "헌트\n",
      "앵커\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 5년간의 영화 데이터 CSV 파일 읽기\n",
    "movies_data = pd.read_csv(\"0530_dataset\\years_moive_data.csv\")\n",
    "\n",
    "# 받아온 파일의 CSV 데이터 읽기\n",
    "received_data = pd.read_csv(\"0530_dataset\\preprosessing_ver8_r4.csv\")\n",
    "\n",
    "# 받아온 파일의 'Distributors_mv' 열을 ,를 기준으로 분할하여 리스트로 만듭니다.\n",
    "received_distributors_mv_list = received_data['Distributors_mv'].str.split(',')\n",
    "\n",
    "# 받아온 파일의 'Release_Date'를 datetime 형식으로 변환\n",
    "received_data['Release_Date'] = pd.to_datetime(received_data['Release_Date'])\n",
    "\n",
    "# 영화 데이터와 받아온 파일의 데이터를 비교하고 조건에 따라 처리\n",
    "for index, row in movies_data.iterrows():\n",
    "    # 받아온 파일의 Distributors_mv 리스트에 포함된 경우 제외\n",
    "    if row['Movie_Title'] in received_distributors_mv_list.values:\n",
    "        continue\n",
    "    \n",
    "    # 받아온 파일의 Movie_Title과 영화 데이터의 Movie_Title이 동일한 경우 처리\n",
    "    if row['Movie_Title'] in received_data['Movie_Title'].values:\n",
    "        # 해당 영화의 Release_Date가 받아온 파일의 Release_Date로부터 3년 이내인 경우에만 처리\n",
    "        release_date = received_data.loc[received_data['Movie_Title'] == row['Movie_Title'], 'Release_Date'].iloc[0]\n",
    "        if pd.to_datetime(row['Release_Date']) <= release_date + pd.DateOffset(years=3):\n",
    "            # Cumulative_Audience를 Distributors_mv_au 열에 저장\n",
    "            received_data.at[index, 'Distributors_mv_au'] = row['Cumulative_Audience']\n",
    "            print(row['Movie_Title'])\n",
    "\n",
    "# Distributors_mv_au 열의 평균을 구하여 NaN 값은 제외하고 채움\n",
    "avg_cumulative_audience = received_data['Distributors_mv_au'].mean(skipna=True)\n",
    "\n",
    "# Distributors_mv_au 열의 NaN 값을 평균 값으로 채움\n",
    "received_data['Distributors_mv_au'].fillna(avg_cumulative_audience, inplace=True)\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장\n",
    "received_data.to_csv(\"0530_dataset\\preprosessing_ver8_r5.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b0445-cf9a-4e8f-bd86-d44b6f6aedaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1번 csv 파일 읽기\n",
    "df1 = pd.read_csv('0530_dataset\\preprosessing_ver8_r4.csv')\n",
    "\n",
    "# 영화 데이터 csv 파일 읽기\n",
    "df_movie = pd.read_csv('0530_dataset\\years_moive_data.csv')\n",
    "\n",
    "# Distributors_mv_au 열 생성\n",
    "df1['Distributors_mv_au'] = None\n",
    "\n",
    "# 각 행에 대한 작업 수행\n",
    "for index, row in df1.iterrows():\n",
    "    mv_titles = row['Distributors_mv'].split(',')\n",
    "    cumulative_audience = 0\n",
    "    count = 0\n",
    "    print(index)\n",
    "    \n",
    "    for mv_title in mv_titles:\n",
    "        # 영화 데이터와 1번 csv 파일의 영화 제목이 같으면 건너뜀\n",
    "        if mv_title == df1.iloc[index]['Movie_Title']:\n",
    "            continue\n",
    "        \n",
    "         # 영화 데이터와 1번 csv 파일의 영화 제목이 같고, 3년 이내의 영화일 경우에만 Cumulative_Audience를 누적하여 계산\n",
    "        movie_row = df_movie[(df_movie['Movie_Title'] == mv_title) & (pd.to_datetime(df_movie['Release_Date']) >= pd.to_datetime(row['Release_Date'])) & (pd.to_datetime(df_movie['Release_Date']) <= pd.to_datetime(row['Release_Date']) + pd.DateOffset(years=3))]\n",
    "        if not movie_row.empty:\n",
    "            cumulative_audience += movie_row.iloc[0]['Cumulative_Audience']  # 해당 영화 데이터의 Cumulative_Audience를 가져와 누적합니다.\n",
    "            count += 1\n",
    "    \n",
    "    # Cumulative_Audience가 있는 경우에만 평균 계산\n",
    "    if count != 0:\n",
    "        avg_cumulative_audience = cumulative_audience / count\n",
    "        df1.at[index, 'Distributors_mv_au'] = avg_cumulative_audience\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장\n",
    "df1.to_csv(\"0530_dataset\\preprosessing_ver8_r5.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf479149-a9ab-445b-82fc-c3276099bdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
